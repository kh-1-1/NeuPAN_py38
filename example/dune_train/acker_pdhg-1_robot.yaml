robot:
  kinematics: 'acker'
  length: 4.6
  width: 1.6
  wheelbase: 3

device: cuda

# Start from the converged learned-prox checkpoint, then KKT fine-tune
#pan:
#  dune_checkpoint: example/dune_train/model/acker_learned_prox_robot/model_2500.pth

train:
  # KKT fine-tune on top of learned-prox
  direct_train: true
  model_name: acker_pdhg-1_robot
  projection: none          # keep learned prox in the loop

  # Feasibility + KKT (balanced)
  use_lconstr: false
  w_constr: 0.10               # keep feasibility pressure
  use_kkt: false
  w_kkt: 1e-3                  # smaller KKT weight to avoid overwhelming loss scale
  kkt_rho: 0.50                # start mid-range; tune in [0.1, 1.0]

  # PDHG-Unroll (optional)
  # Set unroll_J>0 to enable; tau/sigma are step sizes; learnable toggles learning them
  unroll_J: 1                  # 0=disabled; 1/2/3 to enable PDHG unroll
  pdhg_tau: 0.5
  pdhg_sigma: 0.5
  pdhg_learnable: false        # true to learn step sizes (Stage 3)
  pdhg_per_step: false         # true to learn per-step parameters (advanced)

  # SE(2) embedding (optional; interface only)
  se2_embed: false             # true to enable SE(2)-aware input encoding (if implemented)

  # Data/training schedule
  data_size: 100000
  data_range: [-25, -25, 25, 25]
  batch_size: 256
  epoch: 2500
  valid_freq: 2
  save_freq: 500
  lr: 5e-5                     # restore baseline LR to allow trunk updates
  lr_decay: 0.5
  decay_freq: 700
