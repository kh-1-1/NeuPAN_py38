# 4. 训练策略

为了训练出既具备高性能又严格遵守物理约束的PDPL-Net，本文提出了一套融合全合成数据生成与物理信息引导的训练框架。本章详细介绍数据集的构建流程，深入阐述核心的KKT残差正则化损失函数——这是连接深度学习与凸优化理论的关键桥梁，并给出完整的训练配置和实践技巧。

## 4.1 训练数据生成

### 4.1.1 合成点云生成

由于PDPL-Net在点级别进行对偶变量预测，我们需要构建一个覆盖机器人周围工作空间的高质量数据集。与依赖人工标注或实际采集的传统数据集不同，我们采用"求解器在环"（Solver-in-the-Loop）的全合成方式生成数据。这种方法不仅保证了标签的数学精确性，还实现了对数据分布的完全控制，能够针对性地覆盖边界区域和困难样本。

数据集$\mathcal{D} = \{(\mathbf{p}_i, \mathbf{G}, \mathbf{g}, \mu^*_i, y^*_i)\}_{i=1}^M$包含$M=150,000$个样本。每个样本由障碍物点$\mathbf{p}_i$、机器人几何参数$(\mathbf{G}, \mathbf{g})$以及对应的最优对偶变量$(\mu^*_i, y^*_i)$组成。点云生成遵循以下原则：

**重要性采样**。在机器人周围$[-10m, 10m] \times [-10m, 10m]$的局部区域内进行采样。考虑到避障约束在接近机器人边界时最为活跃（即这些约束是"紧"的），我们在机器人轮廓附近的$0.5m$范围内采用更高密度的采样策略。具体而言，50%的样本在距离机器人边界0–0.5m的环形区域内采样，30%在0.5–2m区域，20%在2–10m区域。这种非均匀采样确保了网络在关键决策区域——即机器人即将接触障碍物的区域——获得充足的训练样本。

**几何多样性**。为了提升模型的泛化能力，我们在数据生成过程中引入了一定程度的几何扰动。机器人的航向角在$[-\pi, \pi]$范围内均匀采样，线速度在$[0, v_{max}]$范围内采样。这使得$\mathbf{G}$和$\mathbf{g}$在训练集中呈现多样化的分布，网络能够学习到不同姿态下的对偶变量预测规律。

### 4.1.2 精确标签生成

对于每一个采样的障碍物点$\mathbf{p}_i$，我们调用工业级二阶锥规划（SOCP）求解器ECOS精确求解第2章定义的对偶优化问题。求解器返回的最优对偶变量$\mu^*_i$和$y^*_i$被记录为训练标签。ECOS求解器基于内点法，能够以$10^{-8}$量级的数值精度求解凸优化问题，确保了标签的高质量。单个点的求解时间约为0.2–0.3毫秒，整个数据集的标签生成在多核CPU上约需数小时。

为了验证标签的正确性，我们对生成的$(\mu^*, y^*)$进行KKT条件检验：（1）原始可行性：$\|\mathbf{G}^\top \mu^* + \lambda^*\| < \epsilon$；（2）对偶可行性：$\mu^* \geq -\epsilon$且$\|\lambda^*\|_2 \leq 1 + \epsilon$；（3）互补松弛性：$|\mu^{*\top}(\mathbf{G}\mathbf{x} - \mathbf{g} - \mathbf{p})| < \epsilon$。容差$\epsilon$设为$10^{-6}$，不满足条件的样本被剔除并重新生成。最终数据集中所有样本均通过KKT条件验证，保证了标签的数学最优性。

### 4.1.3 数据预处理

为了加速训练收敛并提升数值稳定性，我们对输入和输出进行了标准化处理。输入点坐标$\mathbf{p}$除以数据范围的最大值（10m），使其分布在$[-1, 1]$区间内。机器人几何参数$\mathbf{G}$和$\mathbf{g}$同样进行归一化处理。输出对偶变量$\mu^*$由于本身就满足范数约束，无需额外标准化。这种预处理使得网络各层的激活值保持在合理范围内，避免了梯度消失或爆炸问题。

## 4.2 损失函数设计

### 4.2.1 监督学习损失

传统的深度学习任务通常仅使用均方误差（MSE）来拟合标签。我们的基础监督损失定义为：

$$
\mathcal{L}_{MSE} = \frac{1}{N} \sum_{i=1}^N \left( \|\mu_i - \mu^*_i\|_2^2 + w_y \|y_i - y^*_i\|_2^2 \right)
$$

其中，$N$为批次大小，$w_y$为辅助变量的损失权重（默认设为0.5）。MSE损失引导网络学习从输入到最优解的映射，在训练初期提供了稳定且强的监督信号。然而，仅靠MSE损失训练的网络存在一个根本性问题：它将对偶变量预测视为纯粹的回归任务，忽略了优化问题的内在结构。网络可能学会在训练分布上精确拟合标签，但在分布外（OOD）样本上产生不合理的输出。

### 4.2.2 KKT残差正则化

为了使网络"理解"优化问题的数学结构，我们将KKT条件编码为正则化损失。KKT条件是凸优化问题最优解的充分必要条件，由以下三部分组成：

**原始可行性残差**。对应于对偶问题的线性等式约束$\mathbf{G}^\top \mu + \lambda = 0$：
$$
r_{primal} = \|\mathbf{G}^\top \mu + \lambda\|_2
$$
由于$\lambda = -\mathbf{G}^\top \mu$在我们的设定下自动满足，该残差可简化为对$y$与$-\mathbf{G}^\top \mu$差距的惩罚。

**对偶可行性残差**。对应于不等式约束$\mu \geq 0$和$\|\lambda\|_2 \leq 1$：
$$
r_{dual} = \|\min(0, \mu)\|_2 + \max(0, \|\mathbf{G}^\top \mu\|_2 - 1)
$$
尽管硬投影层在推理阶段保证了对偶可行性，但在训练早期引入该损失有助于网络权重更快收敛到可行域流形附近，减少投影层的修正幅度。

**互补松弛性残差**。这是衡量解的"最优性"的关键指标。它要求对偶变量$\mu$仅在原始约束被激活（即障碍物接触机器人边界）时才非零：
$$
r_{comp} = |\mu^\top (\mathbf{G}\mathbf{x} - \mathbf{g} - \mathbf{p})|
$$
互补松弛性确保了对偶变量与约束边界的正确对齐关系。违反互补松弛性意味着网络在不必要的地方分配了非零对偶变量，这虽然不影响可行性，但会导致次优的距离估计。

**综合KKT损失**。最终的KKT损失定义为三项残差的加权和：
$$
\mathcal{L}_{KKT} = w_p \cdot r_{primal} + w_d \cdot r_{dual} + w_c \cdot r_{comp}
$$
权重设置为$w_p = 0.1$、$w_d = 0.5$、$w_c = 0.05$。对偶可行性权重较大是因为这直接关系到安全性；互补松弛性权重较小是因为该条件在边界处较难精确满足，过大的权重可能干扰其他学习目标。

### 4.2.3 总体损失函数

PDPL-Net的总体损失函数为监督损失和KKT正则化损失的加权和：
$$
\mathcal{L}_{total} = \mathcal{L}_{MSE} + w_{KKT} \cdot \mathcal{L}_{KKT}
$$
其中，$w_{KKT}$为KKT正则化权重。在两阶段训练中，$w_{KKT}$从0逐渐增加到$10^{-3}$，使网络先学会基本的映射关系，再逐步内化物理约束。

## 4.3 两阶段课程学习

由于引入物理约束后的损失曲面变得复杂且非凸，直接进行联合训练容易陷入局部极小或出现训练不稳定。为此，我们设计了两阶段的课程学习策略：

**阶段一：模仿学习（Imitation Phase）**。该阶段的目标是快速建立从输入到输出的粗略映射。训练仅使用$\mathcal{L}_{MSE}$，学习率设为$5 \times 10^{-5}$，共训练2500个epoch。在该阶段结束时，网络能够学会基本的距离感知直觉，输出的对偶变量在数值上接近最优解，但在边界处不够精确，且可能存在一定比例的约束违背。

**阶段二：物理微调（Physics-Informed Fine-tuning）**。该阶段的目标是利用KKT条件精细修正网络参数，提升解的质量和物理一致性。训练引入$\mathcal{L}_{KKT}$（$w_{KKT} = 10^{-3}$），学习率降低为$5 \times 10^{-6}$，共训练2500个epoch。关键的训练技巧是**冻结特征编码器**，仅微调PDHG展开层和残差模块。这种策略基于以下考虑：特征编码器在阶段一已经学会了从点云提取有意义的几何特征，过度调整可能导致特征漂移；而展开层的参数直接影响对偶变量的更新规则，是物理约束发挥作用的主要载体。

实验表明，经过两阶段训练后，网络输出的KKT残差显著降低，且在未见过的测试场景中表现出更强的泛化能力。阶段二的关键贡献在于将优化问题的结构先验"内化"到网络参数中，使网络不仅拟合训练数据的分布，更理解了问题的本质——KKT条件反映的是优化问题的数学不变性，这在任何输入分布下都应该成立。

## 4.4 训练配置

表2汇总了PDPL-Net的完整训练超参数设置。

**表2：训练超参数设置**

| 类别 | 参数 | 值 | 说明 |
|:-----|:-----|:---|:-----|
| **全局** | Batch Size | 256 | 批次大小 |
| | Optimizer | Adam | 优化器 |
| | Data Range | $[-10, 10]^2$ | 采样范围（米） |
| | Dataset Size | 150,000 | 训练样本总数 |
| | Test Size | 2,000 | 测试样本数 |
| **阶段一** | Epochs | 2,500 | 预训练轮数 |
| | Learning Rate | $5 \times 10^{-5}$ | 初始学习率 |
| | LR Scheduler | Step (0.5 / 300) | 每300轮衰减0.5 |
| | Loss | $\mathcal{L}_{MSE}$ only | 仅监督损失 |
| **阶段二** | Epochs | 2,500 | 微调轮数 |
| | Learning Rate | $5 \times 10^{-6}$ | 降低学习率 |
| | $w_{KKT}$ | $10^{-3}$ | KKT正则化权重 |
| | Frozen Layers | Feature Encoder | 冻结编码器 |

**训练技巧**。（1）梯度裁剪：设置梯度范数上界为1.0，防止梯度爆炸；（2）学习率预热：前100个epoch使用线性预热，从0逐渐增加到目标学习率；（3）数据增强：训练时对点云进行随机旋转（$[-\pi, \pi]$）和小幅度平移（$[-0.5m, 0.5m]$），提升泛化性；（4）硬投影层在训练时始终启用，保证训练-推理一致性。

