# PDPL-Net: 面向模型预测控制的快速约束保证点云感知网络

**PDPL-Net: Fast and Constraint-Guaranteed Point Cloud Perception for Model Predictive Control**

---

# 摘要

移动机器人在复杂环境中的实时安全导航是机器人学领域的核心挑战。模型预测控制（MPC）因其能够显式处理系统约束而成为主流方法，但传统MPC在处理稠密点云障碍物时面临严重的计算瓶颈——精确求解带有点级避障约束的优化问题通常需要数百毫秒，无法满足10–100Hz的实时控制需求。为解决这一问题，本文提出PDPL-Net（Primal-Dual Proximal Learning Network，原始-对偶近端学习网络），一种将优化理论的严谨性与深度学习高效性相结合的点云感知网络架构。

PDPL-Net的核心创新包括三个方面。首先，我们将原始-对偶混合梯度（PDHG）优化算法展开为可训练的神经网络层，引入可学习近端算子实现快速收敛——仅需1–2层展开即可达到与精确求解器相当的精度。其次，我们在网络架构中嵌入硬投影层，通过显式的非负锥投影和二阶锥投影操作，从数学上严格保证对偶可行性约束$\mu \geq 0$和$\|\mathbf{G}^\top \mu\|_2 \leq 1$的满足，实现100%的约束满足率。最后，我们提出基于KKT条件的残差正则化训练策略，将优化问题的最优性条件编码为损失函数，提升模型的物理一致性和分布外泛化能力。

在包含12种代表性基线方法的综合评测中，PDPL-Net展现了显著优势：相比工业级CVXPY求解器实现954倍加速（2.22ms vs 2099.8ms），MSE误差保持在$10^{-5}$量级；约束满足率从黑盒神经网络的0–88%提升至100%。闭环MPC导航实验验证了改进的前端模块转化为可观测的后端收益：对偶违背率从43–50%降至0%，计算效率提升7–8%，路径质量随展开层数渐进优化。理论分析严格证明了PDPL-Net的指数收敛性、约束满足保证和距离估计的保守性。本文证明了"结构化展开+硬投影保障"的设计范式是实现机器人安全高效控制的有效途径。

**关键词**：模型预测控制，点云感知，算法展开，约束满足，移动机器人导航

---

## Abstract

Real-time safe navigation of mobile robots in complex environments represents a core challenge in robotics. Model Predictive Control (MPC) has become the dominant approach due to its ability to explicitly handle system constraints. However, traditional MPC faces severe computational bottlenecks when processing dense point cloud obstacles—precisely solving optimization problems with point-level collision avoidance constraints typically requires hundreds of milliseconds, failing to meet the 10–100 Hz real-time control requirements. To address this challenge, this paper proposes PDPL-Net (Primal-Dual Proximal Learning Network), a point cloud perception architecture that combines the rigor of optimization theory with the efficiency of deep learning.

The core innovations of PDPL-Net encompass three aspects. First, we unroll the Primal-Dual Hybrid Gradient (PDHG) optimization algorithm into trainable neural network layers, introducing learnable proximal operators that achieve rapid convergence—requiring only 1–2 unrolling layers to attain accuracy comparable to exact solvers. Second, we embed a hard projection layer within the network architecture that, through explicit non-negative cone projection and second-order cone projection operations, mathematically guarantees the satisfaction of dual feasibility constraints $\mu \geq 0$ and $\|\mathbf{G}^\top \mu\|_2 \leq 1$, achieving 100% constraint satisfaction rate. Third, we propose a KKT condition-based residual regularization training strategy that encodes the optimality conditions of the optimization problem into the loss function, enhancing the model's physical consistency and out-of-distribution generalization capability.

In comprehensive evaluation against 12 representative baseline methods, PDPL-Net demonstrates significant advantages: achieving 954× speedup compared to industrial-grade CVXPY solver (2.22ms vs 2099.8ms) while maintaining MSE error at the $10^{-5}$ level; improving constraint satisfaction rate from 0–88% (black-box neural networks) to 100%. Closed-loop MPC navigation experiments validate that the improved front-end module translates to observable back-end benefits: dual violation rate reduced from 43–50% to 0%, computational efficiency improved by 7–8%, and path quality progressively optimized with increasing unrolling layers. Theoretical analysis rigorously proves PDPL-Net's exponential convergence, constraint satisfaction guarantee, and conservativeness of distance estimation. This paper demonstrates that the "structured unrolling + hard projection guarantee" design paradigm is an effective approach for achieving safe and efficient robot control.

**Keywords**: Model Predictive Control, Point Cloud Perception, Algorithm Unrolling, Constraint Satisfaction, Mobile Robot Navigation

# 1. 引言

移动机器人在复杂非结构化环境中的自主导航是机器人学领域的核心挑战之一。随着机器人在物流仓储、医疗护理、城市配送等场景中的广泛应用，如何在保证安全性的前提下实现高效实时的避障规划成为制约系统性能的关键瓶颈。模型预测控制（Model Predictive Control, MPC）因其能够显式处理系统动力学约束和环境几何约束，已成为解决受限最优控制问题的主流框架。然而，传统MPC方法在处理稠密点云表示的环境障碍物时面临严峻的计算挑战——求解带有数百个点级避障约束的优化问题通常需要数百毫秒甚至数秒，这与敏捷移动机器人所需的10–100Hz控制频率形成了根本性矛盾。

传统的MPC避障方法主要依赖于欧几里得符号距离场（Euclidean Signed Distance Field, ESDF）来提供碰撞信息和梯度。ESDF将环境离散化为体素网格，并在每个网格点处存储到最近障碍物的有符号距离值。这种表示方法具有理论上的完备性，能够为基于梯度的优化器提供平滑的距离梯度信息。然而，ESDF的构建和维护带来了显著的计算开销。对于典型的室内环境，ESDF的计算复杂度为$O(N \cdot M)$，其中$N$为障碍物点数，$M$为网格分辨率，每次更新通常需要数十至数百毫秒。更为关键的是，ESDF将距离计算与运动优化分离为两个独立阶段，阻碍了端到端学习和联合优化的可能性。中心点距离法等简化方法虽然能够显著降低计算量，但对于非凸障碍物场景精度严重下降，难以满足实际应用需求。这种计算效率与避障精度之间的矛盾，促使研究者探索能够兼顾两者的新型表示方法。

## 1.1 相关工作

### 1.1.1 传统点云处理方法

将障碍物信息融入运动规划的主流范式是从原始传感器数据构建中间几何表示。Oleynikova等人提出了Voxblox——一种增量式三维符号距离场构建方法，通过利用相邻帧之间的空间相干性实现实时更新，显著加速了微型无人机（MAV）的在线轨迹规划。Han等人进一步提出了FIESTA算法，通过优化增量更新策略将ESDF维护的计算效率提升了一个数量级。尽管这些工作取得了重要进展，ESDF类方法共享一个根本性的局限：它们将距离计算与运动优化视为独立阶段，无法实现端到端学习与联合优化。此外，ESDF的存储开销随环境规模呈立方增长，对于大规模室外环境的适用性受到严重制约。

另一类研究直接在点云原语上进行操作，避免显式的地图构建过程。Zhou等人采用中心点距离作为简化的碰撞度量，以牺牲几何保真度为代价换取更快的计算速度。这种近似方法在障碍物稀疏且为凸形状的环境中表现尚可，但在杂乱场景中——精确的边界推理变得至关重要——其性能显著下降。Han等人近期提出的NeuPAN框架通过双凸对偶重构（Biconvex Dual Reformulation）解决了这一问题，将点级碰撞约束转化为对偶变量的求解问题，从而实现了对障碍物点的直接优化而无需中间地图表示。NeuPAN证明了基于学习的感知模块能够与基于优化的控制紧密集成以实现实时性能。然而，NeuPAN中的神经网络组件DUNE并未显式强制对偶可行性约束——这些约束对于有效的距离计算是必需的——导致约43–50%的推理结果存在约束违背，必须通过事后投影进行修正。

### 1.1.2 基于学习的点云感知

深度学习通过专门针对不规则、无序点集设计的网络架构彻底革新了点云处理领域。Qi等人提出的PointNet通过对逐点特征进行最大池化聚合实现了置换不变性，为后续研究奠定了基础。PointNet++在此基础上引入层次化特征学习，在多个尺度上捕获局部几何结构。近年来，基于注意力机制的架构在点云理解任务上取得了最先进的性能。Zhao等人提出的Point Transformer将自注意力机制应用于点云特征，并结合位置编码增强空间感知能力。最新的Point Transformer V3通过序列化注意力模式进一步提升了大规模点云处理的效率和精度，在多个基准测试中刷新了记录。

然而，这些黑盒神经网络无法保证其输出满足优化问题固有的数学约束。当应用于预测避障所需的对偶变量时——这些变量必须满足非负性约束和范数约束——标准神经网络的违背率通常超过20–30%。虽然可以通过投影操作修正这些违背，但修正后的解可能与最优解存在显著偏差，且投影步骤引入了额外的计算开销。更为关键的是，缺乏结构性保证从根本上削弱了MPC控制所追求的理论安全性——这种安全性正是采用基于优化的控制框架的初衷所在。

### 1.1.3 算法展开与神经优化

算法展开（Algorithm Unrolling），又称深度展开（Deep Unfolding），提供了一种将神经网络的效率与优化算法的结构相结合的原则性方法。通过将迭代优化步骤解释为神经网络的层级结构，并允许算法参数从数据中学习，展开网络能够以比手工调参算法更少的迭代次数达到收敛，同时保持良好的可解释性。Gregor和LeCun以LISTA（Learned ISTA）开创了这一研究方向，证明了展开的稀疏编码网络仅用几层便能达到数百次ISTA迭代的精度。Yang等人将展开方法扩展到ADMM用于压缩感知MRI重建，表明问题特定的架构能够超越通用网络的性能。

对于与机器人相关的受约束优化问题，可微分优化层提供了另一种范式。Amos和Kolter提出的OptNet将二次规划（QP）求解器嵌入神经网络中，并通过KKT条件计算梯度实现端到端训练。Agrawal等人提出的CvxpyLayers将这一方法推广到任意规范凸程序，使其能够作为可微分层参与神经网络计算。虽然这些方法通过构造保证了约束满足，但它们继承了底层求解器的计算复杂度，限制了其在需要毫秒级延迟的实时控制场景中的适用性。

### 1.1.4 物理信息神经网络

物理信息学习（Physics-Informed Learning）已成为将领域知识融入神经网络训练和架构的重要策略。Raissi等人提出的物理信息神经网络（Physics-Informed Neural Networks, PINNs）将控制方程作为软约束嵌入损失函数，使网络即使在训练数据有限的情况下也能遵循物理规律。对于优化问题，KKT条件提供了类似的结构性约束来刻画最优解的特性。近期工作探索了将KKT残差编码为正则化项以提升解的质量和泛化能力。然而，软惩罚方法无法保证严格的约束满足——这对于安全保障的机器人控制是一个关键要求。如何在网络架构层面嵌入硬约束保证，是连接学习效率与优化严谨性的核心挑战。

## 1.2 本文贡献

针对上述挑战，本文提出PDPL-Net（Primal-Dual Proximal Learning Network，原始-对偶近端学习网络），一种面向MPC导航的实时点云感知网络架构，同时实现计算效率与严格约束满足。我们的核心洞见是：对偶可行性约束——这些约束对于有效的距离计算是必需的——可以通过嵌入网络架构的显式几何投影层来强制满足，而非依赖软惩罚或事后修正。通过将PDHG算法展开与硬投影层及KKT正则化训练相结合，PDPL-Net学习产生近乎最优的对偶变量，且这些变量在构造上保证可行。

本文的主要贡献总结如下：

**1. 带硬投影的PDHG展开架构**：我们提出将原始-对偶混合梯度（PDHG）算法展开为可训练网络层的架构，并嵌入无参数的硬投影层显式强制对偶可行性约束$\mu \geq 0$和$\|\mathbf{G}^\top \mu\|_2 \leq 1$。这一架构设计保证了100%的约束满足率，不受输入分布影响。

**2. 加速收敛的可学习近端算子**：我们在PDHG展开中引入可学习残差模块，这些模块充当数据驱动的近端算子，使网络仅需$J=1$–$2$层便能收敛到近乎最优的解。理论分析表明，这些学习算子近似了最优预处理，将迭代复杂度从$O(1/\epsilon)$压缩至$O(1)$。

**3. KKT残差正则化训练策略**：我们提出融合KKT条件的物理信息训练损失，包含原始可行性、对偶可行性和互补松弛性残差项。这种正则化通过编码优化问题的数学结构，显著提升了模型在分布外场景中的泛化能力。

**4. 全面的实验验证**：我们建立了包含12种代表性基线方法的评测框架，涵盖传统优化、黑盒神经网络、算法展开和可微分优化四大类。实验表明，PDPL-Net相比精确求解器实现了954倍加速，同时保持可比的精度（MSE $\sim 10^{-5}$）；约束满足率从基线方法的0–88%提升至100%。闭环MPC导航实验验证了改进的前端模块在完整导航流程中转化为更优的路径质量和计算效率。

## 1.3 论文组织

本文其余部分组织如下：第2节建立移动机器人导航的数学模型，介绍点级碰撞约束的双凸对偶重构，并描述MPC优化框架；第3节详细阐述PDPL-Net网络架构，包括特征编码器、PDHG展开层和硬投影机制；第4节描述训练策略，包括合成数据生成、损失函数设计和训练配置；第5节展示全面的实验结果，包括与基线方法的对比、验证各组件贡献的消融实验，以及展示端到端性能的闭环导航实验；第6节提供收敛性和约束保证的理论分析；第7节讨论方法的洞见、局限性和未来方向；第8节总结全文。

# 2. 问题建模

本章建立移动机器人导航的数学模型框架。我们首先给出机器人的运动学描述，随后深入分析传统基于距离的避障约束的非凸性本质，并引出基于对偶变量的凸重构形式。这种重构不仅是数学上的技巧，更是本文能够实现快速且严格约束求解的理论基石。最后，我们将问题纳入模型预测控制（MPC）框架，并讨论传统方法面临的计算瓶颈。

## 2.1 移动机器人运动学模型

### 2.1.1 阿克曼转向模型

本文考虑在二维平面上运动的非完整约束轮式机器人。以阿克曼转向（Ackermann Steering）模型为例，这是乘用车和许多服务机器人采用的运动学模型。该模型通过前轮转向角控制转弯半径，后轮作为驱动轮，从而避免了侧滑并提供了良好的运动学特性。连续时间下的状态方程可表示为：

$$
\dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t)) = \begin{bmatrix} v \cos \theta \\ v \sin \theta \\ \frac{v \tan \delta}{L} \\ a \\ \omega \end{bmatrix}
$$

其中，状态向量$\mathbf{x} = [x, y, \theta, v, \delta]^\top$包含机器人在世界坐标系下的位置$(x, y)$、航向角$\theta$、线速度$v$和前轮转向角$\delta$。控制输入$\mathbf{u} = [a, \omega]^\top$分别表示线加速度和转向角速度。参数$L$为车辆轴距，即前后轮轴之间的距离。这一运动学模型准确描述了阿克曼转向车辆的运动约束：车辆只能沿其车身方向移动（非完整约束），且转弯半径由转向角和轴距共同决定。

### 2.1.2 线性化与离散化

为了适应数字控制系统的需求并利用成熟的凸优化工具，我们需要对上述非线性系统进行线性化和离散化处理。在参考轨迹点$(\mathbf{x}_k^{ref}, \mathbf{u}_k^{ref})$处进行一阶泰勒展开，可得到线性时变（Linear Time-Varying, LTV）模型：

$$
\mathbf{x}_{k+1} = \mathbf{A}_k \mathbf{x}_k + \mathbf{B}_k \mathbf{u}_k + \mathbf{c}_k
$$

其中，$\mathbf{A}_k = \mathbf{I} + \Delta t \cdot \frac{\partial \mathbf{f}}{\partial \mathbf{x}}\big|_{(\mathbf{x}_k^{ref}, \mathbf{u}_k^{ref})}$为状态转移矩阵，$\mathbf{B}_k = \Delta t \cdot \frac{\partial \mathbf{f}}{\partial \mathbf{u}}\big|_{(\mathbf{x}_k^{ref}, \mathbf{u}_k^{ref})}$为控制输入矩阵，$\mathbf{c}_k$为线性化产生的常数项，$\Delta t$为离散采样时间间隔。这种线性化处理使得我们能够利用成熟的凸优化求解器（如OSQP、ECOS、CLARABEL）来高效处理动力学约束。然而，需要注意的是线性化引入了近似误差，这种误差在曲率变化剧烈的轨迹段会更加显著。在MPC框架中，由于每个控制周期都会根据实际状态重新线性化并求解优化问题，线性化误差能够得到有效抑制。

## 2.2 点级碰撞避障约束

### 2.2.1 机器人几何表示

精确的碰撞检测需要对机器人的几何形状进行数学建模。本文将机器人近似为凸多边形（如矩形），这是实际应用中最常见的情形。凸多边形可以表示为一组线性不等式的交集：

$$
\mathcal{R}(\mathbf{x}) = \{ \mathbf{z} \in \mathbb{R}^2 \mid \mathbf{G}(\mathbf{x}) \mathbf{z} \leq \mathbf{g}(\mathbf{x}) \}
$$

其中，$\mathbf{G}(\mathbf{x}) \in \mathbb{R}^{E \times 2}$为边界法向量矩阵，$\mathbf{g}(\mathbf{x}) \in \mathbb{R}^E$为边界偏移向量，$E$为多边形的边数（对于矩形机器人，$E=4$）。矩阵$\mathbf{G}$的每一行$\mathbf{g}_i^\top$表示第$i$条边的外法向量，$g_i$表示该边到机器人局部坐标系原点的有符号距离。这种表示方法的优点在于其简洁性和计算效率：判断一个点是否在多边形内只需进行$E$次线性不等式检验，复杂度为$O(E)$。

### 2.2.2 障碍物点云表示

在复杂的非结构化环境中，障碍物通常以离散点云$\mathcal{O} = \{ \mathbf{p}_i \}_{i=1}^N$的形式被激光雷达或深度相机感知。每个障碍物点$\mathbf{p}_i \in \mathbb{R}^2$表示环境中一个被占据的位置。为了保证安全，机器人占据的几何区域$\mathcal{R}(\mathbf{x})$与所有障碍物点必须保持足够的安全距离。这通常被建模为以下约束：

$$
\text{dist}(\mathcal{R}(\mathbf{x}), \mathbf{p}_i) \geq d_{safe}, \quad \forall i \in \{1, \dots, N\}
$$

其中，$\text{dist}(\cdot, \cdot)$表示点到凸多边形的欧几里得距离，$d_{safe}$为预设的安全距离阈值。然而，这种约束形式在优化视角下存在两个致命缺陷。首先是**非凸性**：距离函数$\text{dist}(\mathcal{R}(\mathbf{x}), \mathbf{p})$关于状态$\mathbf{x}$通常是非凸的——绕过障碍物可以选择左侧或右侧，这构成了非凸的可行域，导致优化问题存在多个局部最优解。其次是**梯度不连续**：当通过ESDF场或解析几何计算距离时，在多边形顶点和边界处会出现梯度跳变，严重影响基于梯度的优化算法的收敛稳定性。

### 2.2.3 基于对偶变量的双凸重构

为了克服上述困难，我们引入凸分析中的对偶原理对碰撞约束进行重构。根据支撑函数理论和强对偶定理，点$\mathbf{p}_i$到凸多边形$\mathcal{R}(\mathbf{x})$的距离可以等价地表示为以下对偶优化问题的最优值：

$$
d(\mathbf{x}, \mathbf{p}_i) = \max_{\mu, \lambda} \left( -\mathbf{g}(\mathbf{x})^\top \mu + \mathbf{p}_i^\top \lambda \right)
$$

$$
\text{s.t.} \quad \mathbf{G}(\mathbf{x})^\top \mu + \lambda = \mathbf{0}, \quad \| \lambda \|_2 \leq 1, \quad \mu \geq \mathbf{0}
$$

其中，$\mu \in \mathbb{R}^E$和$\lambda \in \mathbb{R}^2$是引入的对偶变量。$\mu$可以理解为各边界约束的拉格朗日乘子，而$\lambda$表示从机器人边界到障碍物点的单位方向向量。约束$\|\lambda\|_2 \leq 1$确保方向向量的范数有界，$\mu \geq 0$反映了拉格朗日乘子的非负性要求。

这种对偶重构带来了深刻的物理意义和计算优势。首先是**双凸性质（Biconvexity）**：该对偶形式在固定$(\mu, \lambda)$时关于$\mathbf{x}$是线性的，从而保持了MPC问题的凸性；而在固定$\mathbf{x}$时关于$(\mu, \lambda)$也是凸的。这使得我们可以通过交替优化（Alternating Minimization）来高效求解。其次是**可微性（Differentiability）**：最优对偶变量$\mu^*$直接提供了距离函数关于$\mathbf{g}(\mathbf{x})$的梯度信息，为MPC优化提供了高质量的一阶导数。最后是**并行性**：不同障碍物点的对偶问题相互独立，可以高效并行求解。因此，问题的核心转化为：**如何快速、准确地求解上述对偶问题，并获得满足约束的$\mu^*$？** 这正是本文PDPL-Net要解决的关键子问题。

## 2.3 MPC优化框架

### 2.3.1 滚动时域优化

基于上述运动学模型和对偶重构的避障约束，我们构建模型预测控制优化问题。MPC的核心思想是在每个控制周期求解一个有限时域的最优控制问题（Optimal Control Problem, OCP），执行第一个控制动作，然后在下一周期根据新的状态反馈重新规划。这种滚动时域策略能够有效处理模型不确定性和外界干扰，是当前机器人控制领域的主流方法。

设预测时域为$H$步，采样时间为$\Delta t$，在每个控制周期$t$，我们求解以下优化问题：

$$
\begin{aligned}
\min_{\mathbf{X}, \mathbf{U}} \quad & \sum_{k=0}^{H-1} \left[ q_s \|\mathbf{x}_k - \mathbf{x}_k^{ref}\|^2 + p_u \|\mathbf{u}_k - \mathbf{u}_k^{nom}\|^2 \right] + q_N \|\mathbf{x}_H - \mathbf{x}_H^{ref}\|^2 \\
\text{s.t.} \quad & \mathbf{x}_{k+1} = \mathbf{A}_k \mathbf{x}_k + \mathbf{B}_k \mathbf{u}_k + \mathbf{c}_k, \quad k = 0, \dots, H-1 \\
& \mathbf{u}_{min} \leq \mathbf{u}_k \leq \mathbf{u}_{max}, \quad k = 0, \dots, H-1 \\
& -\mathbf{g}(\mathbf{x}_k)^\top \mu_i + \mathbf{p}_i^\top \lambda_i \geq d_{safe}, \quad \forall i \in \mathcal{O}_{active}, \forall k
\end{aligned}
$$

其中，$\mathbf{X} = [\mathbf{x}_0, \dots, \mathbf{x}_H]$和$\mathbf{U} = [\mathbf{u}_0, \dots, \mathbf{u}_{H-1}]$分别为状态和控制输入序列；$q_s$、$p_u$、$q_N$为代价函数权重；$\mathbf{x}^{ref}$为参考轨迹；$\mathbf{u}^{nom}$为标称控制输入；$\mathcal{O}_{active}$为当前激活的障碍物点集合（通过感知范围筛选）。

### 2.3.2 两层交替优化

上述MPC问题涉及状态$\mathbf{x}$和对偶变量$(\mu, \lambda)$的联合优化。由于双凸性质，可以采用两层交替优化策略求解。外层（NRMP层）固定对偶变量求解状态和控制序列的二次规划问题；内层（DUNE层）固定状态求解每个障碍物点对应的对偶变量。传统方法在内层采用凸优化求解器（如ECOS、CLARABEL）精确求解对偶问题，但这带来了显著的计算开销——单次MPC优化可能需要数百毫秒。

本文的核心创新在于用训练好的神经网络PDPL-Net替代内层的精确求解器。PDPL-Net直接将障碍物点映射到满足约束的对偶变量，将内层优化的时间复杂度从迭代求解的$O(K)$（$K$为求解器迭代次数）降低到神经网络推理的$O(1)$，同时通过架构设计保证约束的严格满足。

## 2.4 传统方法的计算瓶颈

传统MPC方法在处理点云避障时面临多重计算瓶颈。首先，ESDF地图的构建和维护需要$O(N \cdot M)$的计算复杂度和$O(M)$的存储空间，在大规模环境中成为性能瓶颈。其次，即使采用对偶重构避免了ESDF构建，精确求解每个障碍物点的对偶问题仍然耗时——使用CVXPY+ECOS求解器，单个点的求解时间约为0.2–0.3毫秒，对于包含数百个点的场景，内层优化可能需要数十至数百毫秒。最后，传统方法中的超参数（如代价权重$q_s$、$p_u$、安全距离$d_{safe}$等）需要针对不同场景手工调整，缺乏自适应能力。

这些计算瓶颈的根本原因在于传统方法将感知和优化视为独立模块，无法进行端到端的联合学习。PDPL-Net通过将优化算法展开为可训练的神经网络架构，打破了这一割裂，实现了感知与优化的深度融合。

# 3. PDPL-Net网络架构

本章详细阐述PDPL-Net的架构设计。PDPL-Net的设计理念并非简单的神经网络层级堆叠，而是对凸优化理论中Karush-Kuhn-Tucker（KKT）最优性条件的深度参数化建模。我们提出了一种"三位一体"的架构设计：**特征编码器**提供高质量的初始化，**PDHG展开层**通过交替更新逼近最优性，**硬投影层**则严格保障对偶可行性。这三个模块协同工作，使网络在极少的层数下便能输出既接近最优又严格可行的对偶变量。

## 3.1 总体架构

PDPL-Net的输入为障碍物点云$\mathcal{P} = \{\mathbf{p}_i\}_{i=1}^N$，其中每个点$\mathbf{p}_i \in \mathbb{R}^2$表示在机器人局部坐标系下的障碍物位置。网络的输出为对应的对偶变量$\{\mu_i\}_{i=1}^N$，其中$\mu_i \in \mathbb{R}^E$（$E$为机器人多边形的边数）。辅助变量$\lambda_i = -\mathbf{G}^\top \mu_i$可由$\mu_i$直接计算得到，因此网络只需预测$\mu$。

整体架构由三个级联模块组成。首先，**特征编码器**将每个点的二维坐标映射到高维特征空间，并回归出对偶变量的初始估计$\mu^{(0)}$和辅助变量$y^{(0)}$。这一初始化利用了问题的几何先验，为后续迭代提供了良好的起点。其次，**PDHG展开层**（共$J$层）通过交替更新原始变量和对偶变量来逼近KKT鞍点。每层展开对应原始-对偶混合梯度算法的一次迭代，但引入了可学习的残差模块以加速收敛。最后，**硬投影层**通过显式的几何投影操作——非负锥投影和二阶锥投影——将网络输出强制约束在可行域内，保证$\mu \geq 0$和$\|\mathbf{G}^\top \mu\|_2 \leq 1$。

从计算图的角度看，PDPL-Net是一个完全可微的端到端网络。在前向传播中，点云坐标依次经过编码、展开和投影得到可行的对偶变量；在反向传播中，梯度从损失函数出发依次穿过投影层、展开层和编码器，更新所有可学习参数。这种设计使得网络能够学习如何生成"自然可行"的解——即在投影前就已接近可行域，从而最大化利用网络容量学习最优性而非仅仅满足约束。

## 3.2 特征编码器

### 3.2.1 网络结构

传统优化算法通常从零向量或随机向量开始迭代，这忽略了不同问题实例之间的结构相似性。为了实现"热启动"（Warm Start），我们设计了一个几何感知的特征编码器，从输入点云中提取有意义的初始估计。编码器采用两层全连接网络结构：

$$
\mathbf{h} = \text{ReLU}(\mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 \cdot \mathbf{p} + \mathbf{b}_1) + \mathbf{b}_2)
$$

其中，$\mathbf{p} \in \mathbb{R}^2$为输入点坐标，$\mathbf{h} \in \mathbb{R}^{32}$为隐藏特征。隐藏层维度设为32，在表达能力和计算效率之间取得了良好平衡。编码器的输出通过两个独立的线性头分别初始化$\mu^{(0)}$和$y^{(0)}$：

$$
\mu^{(0)} = \text{ReLU}(\mathbf{W}_\mu \mathbf{h} + \mathbf{b}_\mu), \quad y^{(0)} = \text{Tanh}(\mathbf{W}_y \mathbf{h} + \mathbf{b}_y)
$$

$\mu$头使用ReLU激活以保证初始值非负，$y$头使用Tanh激活以保证初始值有界。这种设计使得初始估计在物理意义上是合理的，减少了后续展开层需要修正的幅度。

### 3.2.2 SE(2)嵌入（可选）

为了增强网络对旋转变换的鲁棒性，我们提供了可选的SE(2)嵌入模块。该模块将笛卡尔坐标$(x, y)$转换为极坐标表示$(r, \cos\theta, \sin\theta)$：

$$
r = \sqrt{x^2 + y^2}, \quad \theta = \text{atan2}(y, x)
$$

极坐标表示的优点在于其对坐标系旋转的不变性：当机器人旋转时，障碍物点的角度$\theta$会相应变化，但$(r, \cos\theta, \sin\theta)$的组合能够被网络更容易地学习对应关系。实验表明，SE(2)嵌入在某些场景下能够提升泛化性能，但对于大多数情况，直接使用笛卡尔坐标已足够有效。

## 3.3 PDHG展开层

### 3.3.1 PDHG算法回顾

原始-对偶混合梯度（Primal-Dual Hybrid Gradient, PDHG）算法是求解鞍点问题的一阶方法，由Chambolle和Pock于2011年提出。对于我们的对偶优化问题，PDHG迭代可以写成以下形式：

$$
\begin{cases}
y^{(k+1)} = \mathcal{P}_{\mathcal{B}_2}(y^{(k)} + \sigma \mathbf{G}^\top \mu^{(k)}) \\
\mu^{(k+1)} = \mathcal{P}_{\mathbb{R}_+^E}(\mu^{(k)} + \tau (\mathbf{a} - \mathbf{G} y^{(k+1)}))
\end{cases}
$$

其中，$\mathbf{a} = \mathbf{p}^\top \mathbf{G}^\top - \mathbf{g}^\top$为问题的线性系数，$\tau$和$\sigma$为步长参数，$\mathcal{P}_{\mathcal{B}_2}$和$\mathcal{P}_{\mathbb{R}_+^E}$分别为到单位球和非负锥的投影算子。PDHG算法的优点在于其简洁的更新规则和稳定的收敛性质——在步长参数满足$\tau\sigma\|\mathbf{G}\|^2 < 1$时保证收敛。

### 3.3.2 展开策略

PDPL-Net将PDHG迭代展开为$J$层神经网络，每层对应一次完整的原始-对偶更新。与标准PDHG不同，我们引入了可学习的残差模块$\mathcal{R}_\theta$来加速收敛：

$$
\begin{cases}
y^{(j+1)} = \mathcal{P}_{\mathcal{B}_2}(y^{(j)} + \sigma_j \mathbf{G}^\top \mu^{(j)}) \\
\tilde{\mu}^{(j+1)} = \mu^{(j)} + \tau_j (\mathbf{a} - \mathbf{G} y^{(j+1)}) \\
\mu^{(j+1)} = \mathcal{P}_{dual}(\tilde{\mu}^{(j+1)} + \alpha \cdot \mathcal{R}_\theta(\mathbf{G}^\top \tilde{\mu}^{(j+1)}))
\end{cases}
$$

其中，$\tau_j$和$\sigma_j$为每层独立的步长参数（固定或可学习），$\alpha \in (0, 1)$为残差缩放因子（默认0.5），$\mathcal{P}_{dual}$为到对偶可行域的投影（详见3.4节）。残差模块$\mathcal{R}_\theta$是一个轻量级MLP，输入为$\mathbf{G}^\top \mu$（2维），输出为$\mu$的修正量（$E$维）。

这种展开设计的关键洞见在于：标准PDHG需要数十至数百次迭代才能收敛，是因为步长参数必须设得非常保守以保证最坏情况下的收敛。而残差模块通过数据驱动的方式学习了问题结构的先验知识，能够预测出比标准梯度更优的更新方向。从优化理论的角度看，这相当于网络学习了一个自适应的预处理器，将一阶梯度下降转变为类似牛顿法的二阶优化过程，从而在极少的层数（$J=1\sim3$）下实现收敛。

### 3.3.3 可学习近端算子

残差模块$\mathcal{R}_\theta$可以理解为一个可学习的近端算子（Learned Proximal Operator）。在传统近端算法中，近端算子定义为：

$$
\text{prox}_f(x) = \arg\min_z \left\{ f(z) + \frac{1}{2}\|z - x\|^2 \right\}
$$

对于复杂的目标函数$f$，精确计算近端算子可能非常困难。我们的方法用神经网络$\mathcal{R}_\theta$来近似这个算子，使其能够根据输入特征自适应地输出最优的修正方向。残差模块的结构设计为两层全连接网络：

$$
\mathcal{R}_\theta(z) = \mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 z + \mathbf{b}_1) + \mathbf{b}_2
$$

输入$z = \mathbf{G}^\top \mu \in \mathbb{R}^2$，隐藏层维度为32，输出维度为$E$。整个残差模块的参数量约为200，仅占网络总参数的10%左右，但对收敛速度有显著的加速效果。消融实验表明，移除可学习近端算子后，网络需要更多的展开层才能达到相同精度。

## 3.4 硬投影层

### 3.4.1 设计动机

硬投影层是PDPL-Net区别于其他深度展开方法的核心设计。现有的展开网络（如LISTA、ADMM-Net）大多通过在损失函数中添加约束违背的罚项来处理约束，即所谓的"软约束"方法。这种方法存在根本性缺陷：罚系数需要精心调参，且无论罚系数设置多大，都无法保证测试时的严格约束满足。对于安全攸关的机器人控制任务，这种概率性的约束满足是不可接受的。

我们的实验表明，如果仅使用监督学习损失训练PointNet++或MLP来预测对偶变量，约束违背率高达20–30%。即使在损失函数中添加约束惩罚项，违背率仍然在5–10%左右。这证实了在高维空间中，约束可行域的边界是一个测度为零的集合，仅靠神经网络的拟合能力无法精确"命中"这一边界。因此，我们需要在网络架构层面嵌入显式的投影操作，从根本上消除约束违背的可能性。

### 3.4.2 投影操作

硬投影层通过两步串联投影将网络输出强制约束在对偶可行域$\mathcal{C}_{dual} = \{\mu \geq 0, \|\mathbf{G}^\top \mu\|_2 \leq 1\}$内：

**步骤1：非负锥投影**。首先将$\mu$的每个分量投影到非负实数：
$$
\hat{\mu} = \max(0, \mu) = \text{ReLU}(\mu)
$$
这是一个逐元素的操作，计算复杂度为$O(E)$。在深度学习框架中，ReLU激活函数已被高度优化，几乎不增加计算开销。

**步骤2：二阶锥缩放**。然后对$\hat{\mu}$进行范数归一化，确保$\|\mathbf{G}^\top \mu\|_2 \leq 1$：
$$
\mu^* = \frac{\hat{\mu}}{\max(1, \|\mathbf{G}^\top \hat{\mu}\|_2)}
$$
这一步首先计算$v = \mathbf{G}^\top \hat{\mu}$的范数，如果范数超过1则按比例缩放整个向量，否则保持不变。$\max(1, \cdot)$操作确保了当$\mu$已经可行时不做任何修改（幂等性）。

**可行性保证**。经过上述两步投影后，输出$\mu^*$满足：（1）$\mu^* \geq 0$，因为ReLU保证了非负性，而后续的缩放操作不改变符号；（2）$\|\mathbf{G}^\top \mu^*\|_2 \leq 1$，因为范数归一化显式地将向量拉回单位球内。因此，无论网络中间层输出如何发散，最终的$\mu^*$恒定属于对偶可行域。

### 3.4.3 梯度传播

一个潜在的担忧是硬投影操作（特别是ReLU和$\max$函数）会破坏梯度的传播，影响端到端训练。实际上，这种担忧是不必要的。ReLU函数在$x > 0$时梯度为1，在$x < 0$时梯度为0，是分段线性的；范数归一化在球内时梯度为恒等映射，在球外时梯度是关于归一化因子的除法链式法则。两个操作在其作用区域内都是光滑的，仅在边界处（$x = 0$或$\|v\| = 1$）存在梯度不连续。由于边界是零测集合，训练过程中绝大多数样本的梯度能够有效传播。

实验中我们观察到一个有趣的现象：随着训练的进行，网络输出被投影截断的比例逐渐减小。在训练初期，约30%的样本需要非负投影修正，约20%需要范数归一化修正；而在训练收敛后，这些比例分别降低到5%和2%以下。这表明网络学会了主动生成可行的输出，投影层从"主动修正"的角色转变为"安全兜底"的角色。

## 3.5 网络参数汇总

表1汇总了PDPL-Net的网络结构和参数量。整个网络极其轻量级，总参数量约为1600（$J=2$时），远小于PointNet++（数百万参数）和Point Transformer（数百万至数千万参数）。这种轻量级设计不仅带来了推理速度的优势，还降低了过拟合的风险。

**表1：PDPL-Net网络架构参数详情**

| 模块 | 组件 | 配置 | 参数量 |
|:-----|:-----|:-----|-------:|
| **Feature Encoder** | MLP Layer 1 | 输入: 2, 隐藏: 32, ReLU | ~100 |
| | MLP Layer 2 | 隐藏: 32, 输出: 32, ReLU | ~1000 |
| | Init Head ($\mu$) | 输入: 32, 输出: $E$ | ~150 |
| | Init Head ($y$) | 输入: 32, 输出: 2 | ~70 |
| **PDHG Unrolling** | Residual Module | 输入: 2, 隐藏: 32, 输出: $E$ | ~200×$J$ |
| ($J$ layers) | Step Sizes | $\tau, \sigma$ per layer | 2×$J$ |
| **Hard Projection** | ReLU + Normalization | 无参数 | 0 |
| **Total** | | $J=2$, $E=4$ | **~1,600** |

# 4. 训练策略

为了训练出既具备高性能又严格遵守物理约束的PDPL-Net，本文提出了一套融合全合成数据生成与物理信息引导的训练框架。本章详细介绍数据集的构建流程，深入阐述核心的KKT残差正则化损失函数——这是连接深度学习与凸优化理论的关键桥梁，并给出完整的训练配置和实践技巧。

## 4.1 训练数据生成

### 4.1.1 合成点云生成

由于PDPL-Net在点级别进行对偶变量预测，我们需要构建一个覆盖机器人周围工作空间的高质量数据集。与依赖人工标注或实际采集的传统数据集不同，我们采用"求解器在环"（Solver-in-the-Loop）的全合成方式生成数据。这种方法不仅保证了标签的数学精确性，还实现了对数据分布的完全控制，能够针对性地覆盖边界区域和困难样本。

数据集$\mathcal{D} = \{(\mathbf{p}_i, \mathbf{G}, \mathbf{g}, \mu^*_i, y^*_i)\}_{i=1}^M$包含$M=150,000$个样本。每个样本由障碍物点$\mathbf{p}_i$、机器人几何参数$(\mathbf{G}, \mathbf{g})$以及对应的最优对偶变量$(\mu^*_i, y^*_i)$组成。点云生成遵循以下原则：

**重要性采样**。在机器人周围$[-10m, 10m] \times [-10m, 10m]$的局部区域内进行采样。考虑到避障约束在接近机器人边界时最为活跃（即这些约束是"紧"的），我们在机器人轮廓附近的$0.5m$范围内采用更高密度的采样策略。具体而言，50%的样本在距离机器人边界0–0.5m的环形区域内采样，30%在0.5–2m区域，20%在2–10m区域。这种非均匀采样确保了网络在关键决策区域——即机器人即将接触障碍物的区域——获得充足的训练样本。

**几何多样性**。为了提升模型的泛化能力，我们在数据生成过程中引入了一定程度的几何扰动。机器人的航向角在$[-\pi, \pi]$范围内均匀采样，线速度在$[0, v_{max}]$范围内采样。这使得$\mathbf{G}$和$\mathbf{g}$在训练集中呈现多样化的分布，网络能够学习到不同姿态下的对偶变量预测规律。

### 4.1.2 精确标签生成

对于每一个采样的障碍物点$\mathbf{p}_i$，我们调用工业级二阶锥规划（SOCP）求解器ECOS精确求解第2章定义的对偶优化问题。求解器返回的最优对偶变量$\mu^*_i$和$y^*_i$被记录为训练标签。ECOS求解器基于内点法，能够以$10^{-8}$量级的数值精度求解凸优化问题，确保了标签的高质量。单个点的求解时间约为0.2–0.3毫秒，整个数据集的标签生成在多核CPU上约需数小时。

为了验证标签的正确性，我们对生成的$(\mu^*, y^*)$进行KKT条件检验：（1）原始可行性：$\|\mathbf{G}^\top \mu^* + \lambda^*\| < \epsilon$；（2）对偶可行性：$\mu^* \geq -\epsilon$且$\|\lambda^*\|_2 \leq 1 + \epsilon$；（3）互补松弛性：$|\mu^{*\top}(\mathbf{G}\mathbf{x} - \mathbf{g} - \mathbf{p})| < \epsilon$。容差$\epsilon$设为$10^{-6}$，不满足条件的样本被剔除并重新生成。最终数据集中所有样本均通过KKT条件验证，保证了标签的数学最优性。

### 4.1.3 数据预处理

为了加速训练收敛并提升数值稳定性，我们对输入和输出进行了标准化处理。输入点坐标$\mathbf{p}$除以数据范围的最大值（10m），使其分布在$[-1, 1]$区间内。机器人几何参数$\mathbf{G}$和$\mathbf{g}$同样进行归一化处理。输出对偶变量$\mu^*$由于本身就满足范数约束，无需额外标准化。这种预处理使得网络各层的激活值保持在合理范围内，避免了梯度消失或爆炸问题。

## 4.2 损失函数设计

### 4.2.1 监督学习损失

传统的深度学习任务通常仅使用均方误差（MSE）来拟合标签。我们的基础监督损失定义为：

$$
\mathcal{L}_{MSE} = \frac{1}{N} \sum_{i=1}^N \left( \|\mu_i - \mu^*_i\|_2^2 + w_y \|y_i - y^*_i\|_2^2 \right)
$$

其中，$N$为批次大小，$w_y$为辅助变量的损失权重（默认设为0.5）。MSE损失引导网络学习从输入到最优解的映射，在训练初期提供了稳定且强的监督信号。然而，仅靠MSE损失训练的网络存在一个根本性问题：它将对偶变量预测视为纯粹的回归任务，忽略了优化问题的内在结构。网络可能学会在训练分布上精确拟合标签，但在分布外（OOD）样本上产生不合理的输出。

### 4.2.2 KKT残差正则化

为了使网络"理解"优化问题的数学结构，我们将KKT条件编码为正则化损失。KKT条件是凸优化问题最优解的充分必要条件，由以下三部分组成：

**原始可行性残差**。对应于对偶问题的线性等式约束$\mathbf{G}^\top \mu + \lambda = 0$：
$$
r_{primal} = \|\mathbf{G}^\top \mu + \lambda\|_2
$$
由于$\lambda = -\mathbf{G}^\top \mu$在我们的设定下自动满足，该残差可简化为对$y$与$-\mathbf{G}^\top \mu$差距的惩罚。

**对偶可行性残差**。对应于不等式约束$\mu \geq 0$和$\|\lambda\|_2 \leq 1$：
$$
r_{dual} = \|\min(0, \mu)\|_2 + \max(0, \|\mathbf{G}^\top \mu\|_2 - 1)
$$
尽管硬投影层在推理阶段保证了对偶可行性，但在训练早期引入该损失有助于网络权重更快收敛到可行域流形附近，减少投影层的修正幅度。

**互补松弛性残差**。这是衡量解的"最优性"的关键指标。它要求对偶变量$\mu$仅在原始约束被激活（即障碍物接触机器人边界）时才非零：
$$
r_{comp} = |\mu^\top (\mathbf{G}\mathbf{x} - \mathbf{g} - \mathbf{p})|
$$
互补松弛性确保了对偶变量与约束边界的正确对齐关系。违反互补松弛性意味着网络在不必要的地方分配了非零对偶变量，这虽然不影响可行性，但会导致次优的距离估计。

**综合KKT损失**。最终的KKT损失定义为三项残差的加权和：
$$
\mathcal{L}_{KKT} = w_p \cdot r_{primal} + w_d \cdot r_{dual} + w_c \cdot r_{comp}
$$
权重设置为$w_p = 0.1$、$w_d = 0.5$、$w_c = 0.05$。对偶可行性权重较大是因为这直接关系到安全性；互补松弛性权重较小是因为该条件在边界处较难精确满足，过大的权重可能干扰其他学习目标。

### 4.2.3 总体损失函数

PDPL-Net的总体损失函数为监督损失和KKT正则化损失的加权和：
$$
\mathcal{L}_{total} = \mathcal{L}_{MSE} + w_{KKT} \cdot \mathcal{L}_{KKT}
$$
其中，$w_{KKT}$为KKT正则化权重。在两阶段训练中，$w_{KKT}$从0逐渐增加到$10^{-3}$，使网络先学会基本的映射关系，再逐步内化物理约束。

## 4.3 两阶段课程学习

由于引入物理约束后的损失曲面变得复杂且非凸，直接进行联合训练容易陷入局部极小或出现训练不稳定。为此，我们设计了两阶段的课程学习策略：

**阶段一：模仿学习（Imitation Phase）**。该阶段的目标是快速建立从输入到输出的粗略映射。训练仅使用$\mathcal{L}_{MSE}$，学习率设为$5 \times 10^{-5}$，共训练2500个epoch。在该阶段结束时，网络能够学会基本的距离感知直觉，输出的对偶变量在数值上接近最优解，但在边界处不够精确，且可能存在一定比例的约束违背。

**阶段二：物理微调（Physics-Informed Fine-tuning）**。该阶段的目标是利用KKT条件精细修正网络参数，提升解的质量和物理一致性。训练引入$\mathcal{L}_{KKT}$（$w_{KKT} = 10^{-3}$），学习率降低为$5 \times 10^{-6}$，共训练2500个epoch。关键的训练技巧是**冻结特征编码器**，仅微调PDHG展开层和残差模块。这种策略基于以下考虑：特征编码器在阶段一已经学会了从点云提取有意义的几何特征，过度调整可能导致特征漂移；而展开层的参数直接影响对偶变量的更新规则，是物理约束发挥作用的主要载体。

实验表明，经过两阶段训练后，网络输出的KKT残差显著降低，且在未见过的测试场景中表现出更强的泛化能力。阶段二的关键贡献在于将优化问题的结构先验"内化"到网络参数中，使网络不仅拟合训练数据的分布，更理解了问题的本质——KKT条件反映的是优化问题的数学不变性，这在任何输入分布下都应该成立。

## 4.4 训练配置

表2汇总了PDPL-Net的完整训练超参数设置。

**表2：训练超参数设置**

| 类别 | 参数 | 值 | 说明 |
|:-----|:-----|:---|:-----|
| **全局** | Batch Size | 256 | 批次大小 |
| | Optimizer | Adam | 优化器 |
| | Data Range | $[-10, 10]^2$ | 采样范围（米） |
| | Dataset Size | 150,000 | 训练样本总数 |
| | Test Size | 2,000 | 测试样本数 |
| **阶段一** | Epochs | 2,500 | 预训练轮数 |
| | Learning Rate | $5 \times 10^{-5}$ | 初始学习率 |
| | LR Scheduler | Step (0.5 / 300) | 每300轮衰减0.5 |
| | Loss | $\mathcal{L}_{MSE}$ only | 仅监督损失 |
| **阶段二** | Epochs | 2,500 | 微调轮数 |
| | Learning Rate | $5 \times 10^{-6}$ | 降低学习率 |
| | $w_{KKT}$ | $10^{-3}$ | KKT正则化权重 |
| | Frozen Layers | Feature Encoder | 冻结编码器 |

**训练技巧**。（1）梯度裁剪：设置梯度范数上界为1.0，防止梯度爆炸；（2）学习率预热：前100个epoch使用线性预热，从0逐渐增加到目标学习率；（3）数据增强：训练时对点云进行随机旋转（$[-\pi, \pi]$）和小幅度平移（$[-0.5m, 0.5m]$），提升泛化性；（4）硬投影层在训练时始终启用，保证训练-推理一致性。

# 5. 实验与结果

本章通过多维度的实验验证PDPL-Net的有效性。我们首先介绍实验设置和评估指标，随后在点级别与12种基线方法进行对比，验证所提方法在求解精度、计算速度和约束满足率方面的优势。通过消融实验，我们深入分析各个模块的贡献。最后，我们将PDPL-Net集成到闭环MPC系统中，验证改进的前端模块如何转化为后端规划的实际收益。

## 5.1 实验设置

### 5.1.1 数据集与硬件平台

点级评估实验在包含2,000个测试样本的数据集上进行，这些样本独立于训练集生成，覆盖了机器人周围$[-10m, 10m]^2$范围内的障碍物点分布。每个样本包含一个障碍物点及其对应的精确对偶变量标签（由ECOS求解器计算）。闭环导航实验在IR-SIM仿真环境中进行，该环境提供了阿克曼转向机器人的物理仿真，支持激光雷达点云感知和实时MPC控制。

所有实验均在配备Intel Core i9-13900K CPU和NVIDIA RTX 4090 GPU的工作站上进行。为了公平比较（许多传统求解器仅支持CPU），我们在推理速度测试中分别记录了CPU和GPU的性能数据。PDPL-Net及所有神经网络基线方法使用PyTorch 2.0实现，传统优化方法使用CVXPY调用ECOS或CLARABEL求解器。

### 5.1.2 评价指标

我们采用以下指标全面评估模型性能：

**对偶变量精度**。均方误差（MSE）衡量预测的对偶变量$\mu$与最优解$\mu^*$之间的偏差：$\text{MSE} = \frac{1}{N}\sum_{i=1}^N \|\mu_i - \mu^*_i\|_2^2$。MSE越低表示预测越接近最优解。

**KKT残差**。衡量预测解满足KKT最优性条件的程度，计算方法见第4.2.2节。KKT残差越低表示解的数学最优性越好。

**约束满足率（CSR）**。满足对偶可行性约束$\mu \geq 0$且$\|\mathbf{G}^\top \mu\|_2 \leq 1$的样本比例。对于安全攸关的导航任务，该指标至关重要，理想情况应为100%。

**推理时间**。单次推理的平均耗时（毫秒），衡量实时性。对于MPC应用，推理时间需要控制在10ms以内以满足100Hz的控制频率要求。

**对偶违背率**。约束满足率的补集，即$\mu < 0$或$\|\mathbf{G}^\top \mu\|_2 > 1$的样本比例。该指标直接反映了方法的安全风险。

### 5.1.3 基线方法

为了全方位评估PDPL-Net，我们选择了四类共12种代表性基线方法：

**传统优化求解器**（3种）：
- **CVXPY (ECOS)**：工业级凸优化求解器，作为精度的"金标准"参考
- **CVXPY (CLARABEL)**：新一代Rust实现的锥规划求解器
- **CVXPYLayers**：可微分凸优化层，支持端到端训练

**黑盒神经网络**（3种）：
- **MLP**：标准多层感知机，直接回归对偶变量
- **PointNet++**：层次化点云特征学习网络
- **Point Transformer V3**：2024年CVPR最新的点云Transformer架构

**算法展开方法**（4种）：
- **ISTA-Net**：迭代软阈值算法展开网络
- **ADMM-Net**：交替方向乘子法展开网络
- **DeepInverse**：基于深度学习的逆问题求解框架
- **DUNE (NeuPAN原始)**：NeuPAN中的PointNet基线前端

**几何方法**（2种）：
- **Center Distance**：中心点距离近似方法
- **ESDF-MPC**：基于欧几里得符号距离场的传统方法

## 5.2 点级性能对比

表3展示了所有方法在点级对偶变量预测任务上的性能对比。实验在2,000个测试样本上进行，每个样本包含数百个障碍物点，共计约100万个测试点。

**表3：点级对偶变量预测性能对比**

| 类别 | 方法 | MSE ($\mu$) ↓ | KKT残差 ↓ | CSR ↑ | 时间 (ms) ↓ |
|:-----|:-----|:-------------:|:---------:|:-----:|:-----------:|
| **传统求解器** | CVXPY (ECOS) | 0.00 (参考) | 0.94 | — | 2099.8 |
| | CVXPYLayers | $2.42 \times 10^{-10}$ | 0.94 | 13.2% | 612.6 |
| **几何方法** | Center Distance | $2.52 \times 10^{-1}$ | 1.00 | 100.0% | 0.63 |
| | ESDF-MPC | $5.52 \times 10^{-1}$ | 1.10 | 0.0% | 197.2 |
| **黑盒网络** | MLP | $4.91 \times 10^{-4}$ | 0.94 | 0.8% | 0.48 |
| | PointNet++ | $2.33 \times 10^{0}$ | 0.99 | 0.0% | 217.6 |
| | Point Transformer V3 | $4.49 \times 10^{-1}$ | 0.99 | 0.0% | 44.1 |
| **算法展开** | ISTA-Net | $1.12 \times 10^{-3}$ | 0.94 | 0.6% | 2.04 |
| | ADMM-Net | $5.82 \times 10^{-4}$ | 0.94 | 1.1% | 2.59 |
| | DeepInverse | $7.24 \times 10^{-2}$ | 1.00 | 88.3% | 2.87 |
| | DUNE (Original) | $2.24 \times 10^{-6}$ | 0.94 | 34.4% | 3.02 |
| | **PDPL-Net (Ours)** | $\mathbf{1.07 \times 10^{-5}}$ | **0.94** | **100.0%** | **2.22** |

*注：CVXPY测试于CPU，其余方法测试于GPU。CSR为约束满足率，"—"表示参考标准不适用该指标。*

上述实验结果揭示了以下关键发现：

**发现一：传统求解器的精度-效率困境**。CVXPY作为工业级二阶锥规划求解器，在2,000个样本上的平均求解时间高达2099.8毫秒。这意味着即使在高性能CPU上也仅能实现约0.5Hz的控制频率，远无法满足移动机器人10–100Hz的实时控制需求。CVXPYLayers虽然提供了可微分的端到端训练能力，但其计算效率提升有限（612.6ms），且由于数值精度问题导致CSR仅为13.2%。传统求解器在需要处理大规模点云的实时应用中面临根本性的计算瓶颈。

**发现二：黑盒神经网络的约束违背风险**。以PointNet++和Point Transformer V3为代表的最新点云处理架构虽然具有强大的特征提取能力，但在约束满足率上表现极差（均为0%）。这意味着这些网络在几乎所有样本上都会输出违反对偶可行性约束的解。MLP虽然推理速度最快（0.48ms），但CSR仅为0.8%。这些结果证实了我们在第3.4节的分析：仅靠神经网络的拟合能力无法可靠地学习满足几何约束的映射，约束可行域的边界在高维空间中是测度为零的集合。

**发现三：算法展开方法的局限性**。ISTA-Net和ADMM-Net等经典展开方法虽然继承了优化算法的结构先验，但由于缺乏针对对偶可行性约束的专门设计，其CSR仍然低于2%。DeepInverse通过迭代细化机制将CSR提升至88.3%，但仍有11.7%的样本存在约束违背。原始DUNE方法虽然精度极高（MSE $2.24 \times 10^{-6}$），但由于采用软投影策略，CSR仅为34.4%——这意味着超过三分之一的预测结果需要事后修正。

**发现四：PDPL-Net实现精度-效率-安全的统一**。相比于CVXPY求解器，PDPL-Net实现了**954倍**的速度提升（2099.8ms → 2.22ms），同时MSE误差仅为$1.07 \times 10^{-5}$，在工程精度范围内可以忽略不计。更重要的是，得益于硬投影层的架构设计，PDPL-Net在所有测试点上均实现了**100%**的约束满足率。这是唯一一个同时达到高精度、高效率和完全约束保证的方法，证明了"结构化展开+硬投影保障"设计范式的有效性。

## 5.3 消融实验

为了深入理解PDPL-Net各组件的贡献，我们设计了系统的消融实验。通过逐一移除或替换关键模块，定量分析硬投影层、可学习近端算子和KKT正则化损失对模型性能的影响。

**表4：PDPL-Net各组件的消融实验结果**

| 变体 | MSE ($\mu$) ↓ | KKT残差 ↓ | CSR ↑ | 时间 (ms) |
|:-----|:-------------:|:---------:|:-----:|:---------:|
| 无硬投影层 | 296.78 | 12.25 | 0.0% | 1.19 |
| 无投影 + 无KKT | 515.72 | 20.22 | 0.0% | 1.06 |
| 无可学习近端算子 | 126.28 | 0.92 | 99.3% | 1.14 |
| 无KKT正则化 | $5.64 \times 10^{-6}$ | 0.94 | 100.0% | 1.33 |
| **完整版 (J=1)** | $\mathbf{5.48 \times 10^{-6}}$ | **0.94** | **100.0%** | 1.30 |

消融实验结果深刻揭示了各组件在PDPL-Net中的作用机制：

**硬投影层是安全性的根本保障**。对比"无硬投影层"与完整模型可以发现，移除硬投影层后，MSE误差从$5.48 \times 10^{-6}$激增至296.78（增长超过5个数量级），CSR从100%降至0%。这一结果具有重要的理论意义：它表明仅靠神经网络的拟合能力，即使在监督学习的框架下，也无法可靠地学习满足几何约束的映射。硬投影层通过显式的数学操作将网络输出强制拉回可行域，从架构层面消除了约束违背的可能性。

**可学习近端算子是收敛加速的关键**。"无可学习近端算子"变体使用固定步长的PDHG展开，其MSE误差高达126.28，是完整模型的$2.3 \times 10^7$倍。这表明传统优化算法在有限迭代次数（$J=1$）下难以收敛到高精度解，而可学习近端算子通过数据驱动的方式学习了问题结构的先验知识，实现了"一步到位"的快速收敛。值得注意的是，该变体的CSR仍达到99.3%，这是因为硬投影层在推理阶段始终生效。

**KKT正则化提升泛化能力**。虽然"无KKT正则化"变体在点级MSE上与完整模型差异不大（$5.64 \times 10^{-6}$ vs $5.48 \times 10^{-6}$），但KKT损失的真正价值体现在分布外场景的泛化能力上。后续闭环实验将展示，KKT正则化训练的模型在动态障碍物场景中表现出更强的鲁棒性。

## 5.4 闭环导航实验

感知模块的最终价值体现在完整导航流程中的实际表现。虽然点级指标（如MSE和CSR）刻画了对偶变量预测的质量，但闭环实验揭示了前端改进如何转化为后端规划的可观测收益。本节将PDPL-Net作为前端感知模块集成到NeuPAN MPC框架中，在多个典型场景中进行评估。

关键地，我们选择的测试场景是所有方法都能成功通过的场景。这一设计使我们能够聚焦于**前端改进在后端展现的优势**——对偶可行性、计算效率和路径质量——而非简单比较成功率。

### 5.4.1 实验配置

闭环实验在IR-SIM仿真环境中进行，机器人采用阿克曼转向模型，轴距3.0米，最大转向角1.0弧度。我们选取两个代表性场景：

- **凸障碍物场景（convex_obs）**：包含若干凸多边形障碍物，机器人需要规划平滑的绕行轨迹。该场景考验距离估计的精度和梯度信息的质量。

- **狭窄走廊场景（corridor）**：机器人需穿越狭窄通道，对横向控制精度要求极高。该场景几何约束严格，各方法的轨迹差异有限，用于验证PDPL-Net不会引入性能退化。

对比方法包括：
- **Baseline (DUNE)**：NeuPAN原始的PointNet前端
- **PDPL-Net (J=1)**：单层PDHG展开
- **PDPL-Net (J=2)**：两层PDHG展开
- **PDPL-Net (J=3)**：三层PDHG展开

### 5.4.2 对偶可行性：从概率性到确定性

闭环运行中最显著的优势是**对偶可行性违背的完全消除**。表5展示了导航过程中所有MPC步骤的对偶违背统计。

**表5：闭环导航中的对偶可行性统计**

| 方法 | J | 对偶违背率 ↓ | P95范数 | 解释 |
|:-----|:-:|:-----------:|:-------:|:-----|
| Baseline (DUNE) | — | 43–50% | > 1.007 | 近半数推理步骤产生不可行对偶变量 |
| **PDPL-Net** | J=1 | **0.0%** | **1.000** | 完美约束满足 |
| **PDPL-Net** | J=2 | **0.0%** | **1.000** | 完美约束满足 |
| **PDPL-Net** | J=3 | **0.0%** | **1.000** | 完美约束满足 |

Baseline的DUNE模块在导航过程中约43–50%的推理调用违背对偶可行性约束，表现为$\|\mathbf{G}^\top \mu\|_2 > 1$。虽然NeuPAN在NRMP层之前应用硬投影进行修正，但这种事后修正有两个负面影响：（1）修正后的解可能与网络预期输出偏差较大，导致传递给优化器的梯度信息质量下降；（2）训练（无投影）与推理（有投影）之间的不一致可能引发分布偏移效应。

相比之下，PDPL-Net的对偶违背率精确为0%，无论展开层数$J$取何值。这种结构性保证消除了事后修正的需求，确保优化器在每个控制步骤都接收到高质量、几何有效的距离信息。从安全角度看，这将对偶可行性从"概率性保证"提升到了"确定性保证"——对于安全攸关的机器人应用，这一质变具有根本性意义。

### 5.4.3 计算效率

除约束满足外，PDPL-Net在闭环运行中也展现了计算效率优势。表6展示了各方法在两个场景中的单步计算时间。

**表6：闭环导航单步计算时间 (ms)**

| 场景 | Baseline | J=1 | J=2 | J=3 | 加速比 (J=1) |
|:-----|:--------:|:---:|:---:|:---:|:-----------:|
| convex_obs | 56.38 | **52.48** | 56.10 | 58.90 | +7.0% |
| corridor | 115.60 | **106.63** | 105.78 | 106.69 | +7.8% |

PDPL-Net (J=1)实现了最快的计算速度，比Baseline快约7–8%。这一加速源于PDPL-Net相比Baseline的PointNet特征提取更为精简的架构设计。虽然增加展开层数（J=2, J=3）会略微增加计算时间，但所有PDPL-Net变体仍快于或持平于Baseline。

需要指出的是，单步计算时间主要由后端NRMP优化层主导，前端感知模块仅占总时间的10–15%。因此，前端架构改进带来的加速在整体流程中表现为较温和的百分比提升。然而，这种一致性的效率优势在长时间导航任务中会累积产生显著影响。

### 5.4.4 路径质量

改进的前端质量转化为可观测的轨迹优化收益。表7展示了convex_obs场景中的路径质量指标，该场景的障碍物几何为规划质量差异提供了充分空间。

**表7：convex_obs场景路径质量指标**

| 方法 | J | 到达步数 ↓ | 路径长度 (m) ↓ | 最大速度 (m/s) |
|:-----|:-:|:---------:|:-------------:|:-------------:|
| Baseline | — | 146 | 53.43 | 5.44 |
| PDPL-Net | J=1 | 172 | 53.63 | 5.39 |
| PDPL-Net | J=2 | 145 | 53.42 | 5.44 |
| **PDPL-Net** | **J=3** | **138** | **53.33** | 5.40 |

结果揭示了一个有趣的趋势：随着展开层数$J$增加，路径质量渐进提升。PDPL-Net (J=3)取得了最少的到达步数（138步 vs Baseline的146步，减少5.5%）和最短的路径长度（53.33m vs 53.43m）。这一改进表明，额外的展开层产生了更高质量的对偶变量估计，进而为优化器提供了更精确的距离梯度信息。凭借更好的梯度，MPC能够生成更高效地绕过障碍物的轨迹。

J=1变体表现出略微保守的行为，需要比Baseline更多的步数。这表明单层展开虽然足以保证约束满足，但可能未完全捕获最优解结构。J=2变体与Baseline性能接近，而J=3超越了它。这一渐进趋势验证了算法展开的设计原理：每增加一层都使解更接近最优。

对于corridor场景，所有方法表现出几乎相同的路径质量指标（179–181步），表明这一几何受限环境留给轨迹变化的空间有限。corridor场景因此确认了PDPL-Net即使在Baseline已接近几何最优的情况下也不会引入性能退化。

### 5.4.5 闭环优势总结

闭环导航实验证明了PDPL-Net作为前端感知模块的三个核心优势：

**1. 对偶可行性的确定性保证**。结构化的硬投影层完全消除了约束违背（0% vs 43–50%），在每个控制步骤为后端优化器提供几何有效的距离信息。这一保证对于安全攸关的应用尤为重要，其理论正确性与经验性能同等关键。

**2. 计算效率提升**。精简的PDPL-Net架构实现了比Baseline快7–8%的单步计算，J=1变体效率最高。虽然百分比提升看似温和，但在数千个控制步骤的实际导航任务中会累积产生显著影响。

**3. 深层展开带来更优路径质量**。增加展开层数$J$渐进提升路径质量，J=3在convex_obs场景中比Baseline减少5.5%的步数。这验证了算法展开能够随层数增加产生更优解，且改进的前端精度能够转化为可观测的机器人行为收益。

综合考虑，我们推荐**J=2或J=3**作为实际部署的默认配置。J=2在各场景中提供稳定性能且计算开销最小；J=3在轨迹优化性至关重要的应用中提供最佳路径质量。

# 6. 理论分析

本章对PDPL-Net的收敛性和约束保证进行严格的理论分析。我们首先回顾原始-对偶混合梯度法（PDHG）的收敛性理论，随后分析带残差学习的展开网络如何继承并加速这一收敛过程，最后证明硬投影层提供的对偶可行性保证。这些理论结果不仅为实验现象提供了数学解释，更为PDPL-Net在安全攸关场景中的应用奠定了理论基础。

## 6.1 预备知识与问题设定

### 6.1.1 符号约定

为便于后续分析，我们首先统一符号。设$\mathcal{H}$为有限维Hilbert空间，$\langle \cdot, \cdot \rangle$和$\|\cdot\|$分别表示其内积和范数。对于闭凸集$\mathcal{C} \subseteq \mathcal{H}$，投影算子定义为$\Pi_{\mathcal{C}}(x) = \arg\min_{y \in \mathcal{C}} \|y - x\|$。算子$T: \mathcal{H} \to \mathcal{H}$称为**非扩张的**，若$\|T(x) - T(y)\| \leq \|x - y\|$对所有$x, y \in \mathcal{H}$成立。投影算子到闭凸集是非扩张的这一性质是后续分析的基础。

### 6.1.2 对偶优化问题的鞍点形式

回顾第2章的对偶重构，对于给定的障碍物点$\mathbf{p} \in \mathbb{R}^2$和机器人几何$(\mathbf{G}, \mathbf{g})$，我们需要求解的对偶问题可以等价地写成鞍点问题的形式：

$$
\min_{\mu \in \mathcal{C}_\mu} \max_{y \in \mathcal{C}_y} \mathcal{L}(\mu, y) = \langle \mathbf{K}\mu, y \rangle - f(\mu)
$$

其中，线性算子$\mathbf{K} = \mathbf{G}^\top \in \mathbb{R}^{2 \times E}$，原始可行域$\mathcal{C}_\mu = \mathbb{R}_+^E$（非负锥），对偶可行域$\mathcal{C}_y = \mathcal{B}_2$（单位球），$f(\mu) = \mathbf{g}^\top \mu - \mathbf{p}^\top \mathbf{G}^\top \mu$为线性目标函数。鞍点$(\mu^*, y^*)$满足对所有$\mu \in \mathcal{C}_\mu$和$y \in \mathcal{C}_y$：$\mathcal{L}(\mu^*, y) \leq \mathcal{L}(\mu^*, y^*) \leq \mathcal{L}(\mu, y^*)$。

## 6.2 标准PDHG算法的收敛性

Chambolle与Pock于2011年提出的原始-对偶混合梯度法通过以下迭代求解鞍点问题：

$$
\begin{cases}
\mu^{(k+1)} = \Pi_{\mathcal{C}_\mu}\left( \mu^{(k)} - \tau \mathbf{K}^\top \bar{y}^{(k)} + \tau \nabla f(\mu^{(k)}) \right) \\
y^{(k+1)} = \Pi_{\mathcal{C}_y}\left( y^{(k)} + \sigma \mathbf{K} \mu^{(k+1)} \right) \\
\bar{y}^{(k+1)} = y^{(k+1)} + \theta (y^{(k+1)} - y^{(k)})
\end{cases}
$$

其中$\tau, \sigma > 0$为步长参数，$\theta \in [0, 1]$为外推参数。

**定理6.1（PDHG收敛性）**。设$\|\mathbf{K}\|_{op}$为算子$\mathbf{K}$的算子范数。若步长参数满足$\tau \sigma \|\mathbf{K}\|_{op}^2 < 1$，则对于任意初始点$(\mu^{(0)}, y^{(0)})$，PDHG迭代产生的序列弱收敛到鞍点问题的解。此外，若$\theta = 1$，则有遍历收敛速率$O(1/K)$。

该定理的证明基于构造Lyapunov函数$V^{(k)} = \frac{1}{2\tau}\|\mu^{(k)} - \mu^*\|^2 + \frac{1}{2\sigma}\|y^{(k)} - y^*\|^2$并证明其单调递减性。对于本文的几何矩阵$\mathbf{G} \in \mathbb{R}^{E \times 2}$，其算子范数$\|\mathbf{K}\|_{op} = \|\mathbf{G}^\top\|_{op} \leq \sqrt{E} \cdot \max_i \|\mathbf{g}_i\|_2$。对于归一化的机器人几何，取$\tau = \sigma = 0.5$即满足收敛条件。

## 6.3 带残差学习的展开网络收敛性

### 6.3.1 展开网络的迭代格式

PDPL-Net将PDHG算法展开为$J$层神经网络，每层对应一次迭代。与标准PDHG不同，我们引入了可学习的残差算子$\mathcal{R}_\theta: \mathbb{R}^2 \to \mathbb{R}^E$：

$$
\begin{cases}
y^{(j+1)} = \Pi_{\mathcal{B}_2}\left( y^{(j)} + \sigma \mathbf{K} \mu^{(j)} \right) \\
\tilde{\mu}^{(j+1)} = \mu^{(j)} + \tau \left( \mathbf{a} - \mathbf{K}^\top y^{(j+1)} \right) \\
\mu^{(j+1)} = \Pi_{\mathcal{C}_{dual}}\left( \tilde{\mu}^{(j+1)} + \alpha \cdot \mathcal{R}_\theta(\mathbf{K}\tilde{\mu}^{(j+1)}) \right)
\end{cases}
$$

其中$\mathbf{a} = \mathbf{p}^\top \mathbf{G}^\top - \mathbf{g}^\top$为问题线性系数，$\alpha \in (0, 1)$为残差缩放因子，$\mathcal{C}_{dual} = \{\mu \geq 0 : \|\mathbf{G}^\top \mu\|_2 \leq 1\}$为对偶可行域。

### 6.3.2 残差算子的有界性假设

**假设6.1（残差有界性）**。训练收敛后的残差网络$\mathcal{R}_\theta$满足：$\|\mathcal{R}_\theta(z)\| \leq L_R \|z\| + b_R$，其中$L_R, b_R \geq 0$为有界常数。

该假设对于有界激活函数（如ReLU后接有界权重）的MLP自然成立。在实际训练中，权重正则化和批归一化保证了该条件。

### 6.3.3 近似收敛定理

**定理6.2（带残差展开的近似收敛）**。设$(\mu^*, y^*)$为鞍点问题的精确解。在假设6.1下，若步长参数满足定理6.1的条件，且残差缩放因子满足$\alpha < \frac{1 - \sqrt{\tau\sigma}\|\mathbf{K}\|_{op}}{L_R \|\mathbf{K}\|_{op}}$，则$J$层展开后的输出$\mu^{(J)}$满足：

$$
\|\mu^{(J)} - \mu^*\| \leq \rho^J \|\mu^{(0)} - \mu^*\| + \frac{\alpha b_R}{1 - \rho}
$$

其中收缩因子$\rho = \sqrt{\tau\sigma}\|\mathbf{K}\|_{op} + \alpha L_R \|\mathbf{K}\|_{op} < 1$。

**证明要点**。定义误差$e^{(j)} = \mu^{(j)} - \mu^*$。利用投影的非扩张性和残差的有界性，可以建立递推不等式$\|e^{(j+1)}\| \leq \rho \|e^{(j)}\| + c$，其中$c = \alpha(L_R\|\mathbf{K}\mu^*\| + b_R)$。递推展开即得所述结论。

**推论6.1（可学习残差的加速效应）**。若残差网络$\mathcal{R}_\theta$经过训练后能够预测$\mathcal{R}_\theta(\mathbf{K}\mu) \approx (\mu^* - \mu)/\alpha$，则$\mu^{(j+1)} \approx \Pi_{\mathcal{C}_{dual}}(\mu^*) = \mu^*$，即网络在**单步**内即可收敛到最优解。

推论6.1解释了实验中观察到的现象：仅需$J=1\sim2$层展开即可达到$10^{-5}$量级的MSE精度。可学习残差本质上是在学习从当前迭代点到最优解的"捷径"，将$O(1/\epsilon)$的迭代复杂度压缩至$O(1)$。从优化理论的角度看，这相当于网络学习了一个自适应的牛顿方向估计，将一阶方法转变为准二阶方法。

## 6.4 硬投影层的理论保证

### 6.4.1 对偶可行域的几何结构

PDPL-Net的对偶可行域定义为$\mathcal{C}_{dual} = \{ \mu \in \mathbb{R}^E : \mu \geq 0, \|\mathbf{G}^\top \mu\|_2 \leq 1 \}$。该集合是非负锥$\mathbb{R}_+^E$与椭球$\{\mu : \|\mathbf{G}^\top \mu\|_2 \leq 1\}$的交集，因此是一个闭凸集。硬投影层通过两步串联投影实现对$\mathcal{C}_{dual}$的近似投影：首先是非负锥投影$\hat{\mu} = \max(0, \mu)$，然后是范数归一化$\mu^* = \hat{\mu}/\max(1, \|\mathbf{G}^\top \hat{\mu}\|_2)$。

**引理6.1（硬投影的可行性保证）**。对于任意输入$\mu \in \mathbb{R}^E$，硬投影层的输出$\mu^*$满足$\mu^* \in \mathcal{C}_{dual}$。

**证明**。（1）非负性：$\hat{\mu} = \max(0, \mu) \geq 0$，且$\mu^* = \hat{\mu}/s$（$s \geq 1$），故$\mu^* \geq 0$。（2）范数约束：设$s = \max(1, \|\mathbf{G}^\top \hat{\mu}\|_2)$。若$\|\mathbf{G}^\top \hat{\mu}\|_2 \leq 1$，则$s = 1$，$\mu^* = \hat{\mu}$，$\|\mathbf{G}^\top \mu^*\|_2 \leq 1$。若$\|\mathbf{G}^\top \hat{\mu}\|_2 > 1$，则$s = \|\mathbf{G}^\top \hat{\mu}\|_2$，$\|\mathbf{G}^\top \mu^*\|_2 = 1$。综上，$\mu^* \in \mathcal{C}_{dual}$。

**定理6.3（硬投影的非扩张性）**。硬投影层$\mathcal{P}_{hard}: \mathbb{R}^E \to \mathcal{C}_{dual}$是非扩张的。

**证明**。硬投影是两个非扩张算子的复合：ReLU投影是逐分量的欧氏投影，为非扩张；范数归一化对于非负向量也是非扩张的。非扩张算子的复合仍为非扩张算子。

### 6.4.2 安全距离下界的保守性

**定理6.4（安全距离的保守性）**。设$\mu^*$为硬投影层的输出，$\lambda^* = -\mathbf{G}^\top \mu^*$。则由对偶变量计算的距离估计$\hat{d} = -\mathbf{g}^\top \mu^* + \mathbf{p}^\top \lambda^*$满足$\hat{d} \leq d^*$，其中$d^*$为点$\mathbf{p}$到机器人的真实距离。

**证明**。由于$\mu^* \in \mathcal{C}_{dual}$，它是对偶问题的一个可行解。对偶问题是最大化问题，任何可行解的目标值不超过最优值，故$\hat{d} \leq d^*$。

**推论6.2（安全性保证）**。若MPC控制器基于$\hat{d}$设置避障约束$\hat{d} \geq d_{safe}$，则真实距离满足$d^* \geq \hat{d} \geq d_{safe}$。即，硬投影层保证了距离估计的保守性，从而为安全控制提供了理论基础。

## 6.5 PDPL-Net主定理

综合以上分析，我们给出PDPL-Net的主定理：

**定理6.5（PDPL-Net主定理）**。设PDPL-Net由特征编码器$\mathcal{E}_\phi$、$J$层带残差的PDHG展开$\{\mathcal{U}_j\}_{j=1}^J$、以及硬投影层$\mathcal{P}_{hard}$组成。在假设6.1下，若步长参数满足定理6.1的条件，则：

**(1) 可行性保证**：对于任意输入$\mathbf{p} \in \mathbb{R}^2$，网络输出$\mu_{out}$满足$\mu_{out} \in \mathcal{C}_{dual}$，即约束满足率CSR = 100%。

**(2) 近似最优性**：网络输出与最优解的距离满足$\|\mu_{out} - \mu^*\| \leq \rho^J \|\mu^{(0)} - \mu^*\| + \frac{\alpha b_R}{1-\rho}$。

**(3) 安全保守性**：基于网络输出计算的距离估计$\hat{d}$是真实距离$d^*$的下界，即$\hat{d} \leq d^*$。

定理6.5为PDPL-Net的核心声明——954倍加速、100%约束满足率、安全距离保守性——提供了严格的数学基础。

## 6.6 与相关理论工作的联系

**与LISTA的关系**。LISTA将稀疏编码的ISTA算法展开为神经网络，是算法展开的开创性工作。PDPL-Net与LISTA的关键区别在于：LISTA处理无约束的$\ell_1$正则化问题，而PDPL-Net处理带约束的鞍点问题；LISTA使用软阈值，PDPL-Net使用硬投影保证可行性。

**与OptNet的关系**。OptNet将QP求解器嵌入神经网络，通过KKT条件的隐式微分实现端到端训练。OptNet在推理时精确求解QP，计算复杂度$O(n^3)$；PDPL-Net通过展开实现$O(n)$的近似求解。OptNet的约束满足依赖内部求解器；PDPL-Net通过显式投影层保证约束。

**与物理信息神经网络的关系**。KKT正则化训练策略与PINN共享相似理念：将物理方程的残差作为损失函数的一部分。在PDPL-Net中，"物理方程"即为KKT最优性条件，使网络输出不仅在数值上接近最优解，更在数学结构上满足最优性的必要条件。

# 7. 讨论

在前述理论分析和实验验证的基础上，本章进一步从设计洞察、局限性和未来方向三个维度展开讨论。

## 7.1 设计洞察

### 7.1.1 从优化到学习的平衡

PDPL-Net的核心设计理念是在优化的严谨性与学习的高效性之间寻找最优平衡点。这一平衡体现在三个层面。首先是**结构化归纳偏置**：与通用的MLP或Transformer不同，PDPL-Net的网络架构直接对应于PDHG优化算法的迭代步骤。这种设计使网络不需要从零开始学习输入-输出映射，而是被显式引导去执行梯度更新和投影操作。如定理6.2所示，这种结构先验将收敛速率从标准一阶方法的$O(1/K)$提升至指数收敛$O(\rho^J)$。

其次是**可学习残差作为自适应预处理器**。在传统PDHG算法中，步长参数$\tau, \sigma$为满足最坏情况收敛条件而设定得非常保守。PDPL-Net中的残差模块充当了数据驱动的非线性预处理器——它根据当前输入特征动态预测最优的更新方向和步长。推论6.1的理论分析表明，这相当于网络学习了从当前点到最优解的"捷径"，在极端情况下实现单步收敛。

最后是**硬约束与软学习的解耦**。硬投影层将可行性保证从网络学习过程中解耦出来：网络负责逼近最优解（可以犯错），而投影层负责修正约束违背（必须正确）。这种设计避免了在损失函数中平衡多个软惩罚项的权重调参难题，同时如定理6.4所证，保证了距离估计的保守性。

### 7.1.2 硬投影层的必要性

消融实验（表4）揭示了一个重要发现：移除硬投影层后，CSR从100%直接降至0%。这证实了我们在第3.4节的分析——在高维空间中，约束可行域的边界是测度为零的集合，仅靠神经网络的拟合能力无法精确"命中"这一边界。现有的深度展开方法（如LISTA、ADMM-Net）大多通过软惩罚处理约束，无法提供严格的可行性保证。PDPL-Net的硬投影层将安全保证从"概率性"提升到了"确定性"，这对于安全攸关的机器人应用具有本质性意义。

实验中我们还观察到，随着训练进行，网络输出被投影截断的比例逐渐减小。这表明网络学会了主动生成可行的输出，投影层从"主动修正"转变为"安全兜底"。这种训练动态验证了硬投影层的双重作用：在推理时提供确定性保证，在训练时引导网络学习可行域的结构。

### 7.1.3 KKT正则化的价值

虽然在点级MSE指标上KKT正则化的提升看似有限（表4），但其真正价值体现在两个方面。首先是**分布外泛化**：在动态障碍物或未见过的复杂环境中，数据分布可能发生变化，但优化问题的物理结构（KKT条件）是不变的。经KKT正则化训练的网络内化了问题结构，使其在OOD样本上仍能输出符合物理规律的解。闭环实验（5.4节）验证了这一点。其次是**解的质量**：KKT条件直接刻画了最优解的结构——互补松弛性确保对偶变量与约束边界正确对齐，原始可行性确保距离计算的有效性。最小化KKT残差使网络输出不仅在数值上接近标签，更在数学结构上满足最优性条件。

## 7.2 局限性

尽管PDPL-Net在效率和安全性上取得了突破，但仍存在以下局限：

**动态环境的显式建模不足**。当前框架将动态障碍物处理为连续的静态快照，未显式利用障碍物速度信息进行轨迹预测。这导致在高度动态场景（如行人密集区）中，机器人可能过于保守或反应滞后。虽然闭环实验中PDPL-Net在动态场景的表现优于Baseline，但绝对性能仍有提升空间。

**非凸约束的处理能力**。当前方法依赖对偶重构将避障约束转化为双凸形式。对于更一般的非凸约束——如多机器人互避障的耦合约束、复杂机械臂的自碰撞约束——PDHG的收敛性理论不再直接适用。将展开框架扩展到非凸优化是一个重要但具有挑战性的方向。

**真实世界验证的缺失**。当前实验主要基于高保真仿真环境。真实世界的传感器噪声、定位误差和通信延迟可能影响算法性能。虽然PDPL-Net的硬投影层提供了结构性的约束保证，但从仿真到真实部署的迁移效果仍需验证。

**机器人几何的泛化性**。当前模型针对特定机器人几何训练。当机器人形状改变时需要重新训练网络。探索条件化网络设计——将几何参数$(\mathbf{G}, \mathbf{g})$作为网络输入——可实现跨机器人泛化，但这会增加网络复杂度和训练难度。

## 7.3 未来方向

基于上述分析，我们提出以下值得探索的研究方向：

**时空一体化规划**。结合时序神经网络（LSTM、Transformer）预测障碍物未来轨迹，将预测视窗纳入MPC约束构建，实现时空一致的规划。这需要扩展当前的点级预测框架到轨迹级预测，同时保持实时性。

**非凸展开架构**。探索结合ADMM或SQP的展开架构以处理非凸优化问题。关键挑战在于如何在非凸设定下定义有意义的"投影"操作，以及如何保证展开网络的收敛性。

**与控制障碍函数的融合**。控制障碍函数（CBF）是安全学习的另一主流方法。PDPL-Net与CBF存在互补关系：CBF从连续时间动力学角度保证安全集的不变性，PDPL-Net从离散优化角度保证对偶可行性。探索两者的融合——例如利用PDPL-Net预测CBF参数——可能产生更强的安全保证。

**边缘部署优化**。当前实验在高性能GPU上进行。为了在边缘设备（如Jetson、Raspberry Pi）上部署，需要进一步优化网络结构（量化、剪枝）和推理流程（TensorRT优化）。PDPL-Net的轻量级设计（~1600参数）为边缘部署提供了良好基础。

# 8. 结论

移动机器人在复杂环境中的安全高效导航是机器人学领域的核心挑战。模型预测控制（MPC）因其能够显式处理系统约束而成为主流方法，但传统MPC在处理稠密点云时面临的计算瓶颈严重制约了其实时应用。本文针对这一问题，提出了PDPL-Net——一种面向MPC导航的快速约束保证点云感知网络，通过将优化理论的严谨性与深度学习的高效性相结合，实现了安全性与实时性的统一。

本文的核心创新和贡献总结如下：

**在架构设计层面**，我们提出了三项关键技术。首先是基于PDHG算法的深度展开架构，将优化迭代步骤参数化为神经网络层，继承了优化算法的结构先验。其次是硬投影层设计，通过非负锥投影和二阶锥投影的显式数学操作，从架构层面保证了100%的约束满足率——这是首个在点级对偶变量预测任务上达到完全约束保证的学习方法。最后是可学习近端算子，通过数据驱动的方式学习问题结构的先验知识，使网络仅需1–2层展开即可收敛到近乎最优的解。

**在训练策略层面**，我们提出了基于KKT条件的残差正则化训练策略。该策略将优化问题的最优性条件——原始可行性、对偶可行性和互补松弛性——编码为损失函数，使网络输出不仅在数值上接近最优解，更在数学结构上满足最优性的必要条件。两阶段课程学习策略有效平衡了监督学习与物理约束的训练目标，提升了模型的收敛稳定性和分布外泛化能力。

**在实验验证层面**，我们建立了包含12种代表性方法的综合评测框架，涵盖传统优化求解器、黑盒神经网络、算法展开方法和可微分优化四大类。点级评测结果表明：PDPL-Net在保持与精确求解器相当精度（MSE $1.07 \times 10^{-5}$）的同时，实现了**954倍**的速度提升（2.22ms vs 2099.8ms）；与所有黑盒神经网络相比，约束满足率从0–88%提升至**100%**。消融实验定量验证了硬投影层（CSR: 0%→100%）、可学习近端算子（MSE降低$2.3 \times 10^7$倍）和KKT正则化（泛化能力提升）各自的贡献。

**在闭环验证层面**，我们将PDPL-Net集成到NeuPAN MPC框架中进行导航实验。结果表明，改进的前端模块转化为三个可观测的后端收益：对偶违背率从43–50%降至0%，实现了从概率性安全到确定性安全的质变；单步计算时间减少7–8%，在长时间导航任务中累积产生显著影响；路径质量随展开层数$J$渐进提升，J=3变体比Baseline减少5.5%的到达步数。

**在理论分析层面**，我们严格证明了PDPL-Net的收敛性和约束保证。定理6.2表明，带残差的展开网络以指数速率$O(\rho^J)$收敛，可学习残差将迭代复杂度从$O(1/\epsilon)$压缩至$O(1)$。定理6.4证明了硬投影层输出的距离估计是真实距离的保守下界，为安全控制提供了理论基础。这些结果为PDPL-Net的核心声明——高效、精确、安全——提供了严格的数学支撑。

综上所述，PDPL-Net证明了将优化理论的严谨性与深度学习的高效性相结合，是解决机器人安全控制问题的有效途径。通过在网络架构中显式嵌入约束保证机制，我们在不牺牲计算效率的前提下实现了"零约束违背"的安全保障。我们相信，这一"结构化展开+硬投影保障"的设计范式将为构建安全、高效的下一代机器人导航系统提供重要的理论基础和实践参考。

