# 1. Introduction

Autonomous navigation in cluttered and unstructured environments represents one of the most challenging problems in mobile robotics. As robots increasingly operate alongside humans in warehouses, hospitals, and urban streets, the demand for real-time collision-free motion planning with formal safety guarantees has become paramount. Model Predictive Control (MPC) offers a principled framework for addressing this challenge by explicitly incorporating dynamic constraints and obstacle avoidance requirements into an online optimization problem. However, the computational burden of solving such constrained optimization problems in real-time—particularly when dealing with dense point cloud representations of the environment—remains a significant bottleneck that limits deployment on resource-constrained robotic platforms.

Traditional approaches to obstacle avoidance in MPC predominantly rely on distance field representations such as the Euclidean Signed Distance Field (ESDF). While ESDF provides smooth gradient information that facilitates gradient-based optimization, its construction and maintenance impose substantial computational overhead. For a typical indoor environment discretized into a voxel grid, ESDF computation scales as $O(N \cdot M)$ where $N$ denotes the number of obstacle points and $M$ the grid resolution, often requiring hundreds of milliseconds per update cycle. This latency fundamentally conflicts with the 10–100 Hz control rates demanded by agile mobile robots navigating dynamic environments. Alternative geometric approaches, such as the center-point distance method, offer faster computation but sacrifice accuracy, particularly for non-convex obstacles where the center-point assumption breaks down. The tension between computational efficiency and collision avoidance precision thus motivates the search for new representations that can bridge this gap.

## 1.1 Related Work

### 1.1.1 Traditional Point Cloud Processing Methods

The dominant paradigm for incorporating obstacle information into motion planning involves constructing intermediate geometric representations from raw sensor data. Oleynikova et al. introduced Voxblox, an incremental 3D signed distance field construction method that enables real-time updates for micro aerial vehicle (MAV) planning. While Voxblox significantly accelerates ESDF computation compared to batch methods, it still requires dedicated computational resources and introduces latency proportional to the observed volume. Han et al. proposed FIESTA, which further optimizes incremental ESDF updates by exploiting spatial coherence between consecutive frames. Despite these advances, ESDF-based methods share a fundamental limitation: they treat distance computation and motion optimization as separate stages, precluding end-to-end learning and joint optimization.

An alternative line of work directly operates on point cloud primitives without explicit map construction. Zhou et al. employed center-point distances as a simplified collision metric, achieving faster computation at the cost of geometric fidelity. Such approximations prove adequate for sparse environments with well-separated convex obstacles but degrade in cluttered scenarios where precise boundary reasoning becomes essential. The recent NeuPAN framework proposed by Han et al. addressed this limitation by reformulating point-level collision constraints through a biconvex dual representation, enabling direct optimization over obstacle points without intermediate map construction. NeuPAN demonstrated that learning-based perception modules can be tightly integrated with optimization-based control to achieve real-time performance. However, the neural network component in NeuPAN—termed DUNE—does not explicitly enforce the dual feasibility constraints required for valid distance computation, leading to constraint violations in approximately 40–50% of inference cases that must be corrected through post-hoc projection.

### 1.1.2 Learning-based Point Cloud Perception

Deep learning has revolutionized point cloud processing through architectures specifically designed for irregular, unordered point sets. PointNet introduced permutation-invariant feature aggregation through max-pooling over point-wise features, establishing a foundation for subsequent work. PointNet++ extended this paradigm with hierarchical feature learning that captures local geometric structure at multiple scales. More recently, attention-based architectures have achieved state-of-the-art performance on point cloud understanding tasks. Zhao et al. proposed Point Transformer, applying self-attention mechanisms to point cloud features with position encoding. The latest iteration, Point Transformer V3, further improves efficiency and accuracy through serialized attention patterns optimized for large-scale point clouds.

Despite their representational power, these black-box neural networks provide no guarantees that their outputs satisfy the mathematical constraints inherent to optimization problems. When applied to predict dual variables for collision avoidance—which must satisfy non-negativity and norm constraints—standard neural networks exhibit violation rates exceeding 20–30%. While such violations can be corrected through projection, the resulting solutions may deviate significantly from optimality, and the projection step introduces additional computation. More critically, the lack of structural guarantees undermines the theoretical safety assurances that motivate MPC-based control in the first place.

### 1.1.3 Algorithm Unrolling and Neural Optimization

Algorithm unrolling, also known as deep unfolding, offers a principled approach to combining the efficiency of neural networks with the structure of optimization algorithms. By interpreting iterative optimization steps as layers of a neural network and allowing algorithm parameters to be learned from data, unrolling achieves faster convergence than hand-tuned algorithms while preserving interpretability. Gregor and LeCun pioneered this approach with LISTA (Learned ISTA), demonstrating that unrolled sparse coding networks could achieve the accuracy of hundreds of ISTA iterations with only a few learned layers. Yang et al. extended unrolling to ADMM for compressed sensing MRI, showing that problem-specific architectures outperform generic networks.

For constrained optimization problems relevant to robotics, differentiable optimization layers provide an alternative paradigm. Amos and Kolter proposed OptNet, which embeds quadratic program (QP) solvers within neural networks and computes gradients through the KKT conditions. Agrawal et al. generalized this approach with CvxpyLayers, enabling arbitrary disciplined convex programs to serve as differentiable layers. While these methods guarantee constraint satisfaction by construction, they inherit the computational complexity of the underlying solvers, limiting their applicability to real-time control where millisecond-level latency is required.

### 1.1.4 Physics-Informed Neural Networks

Physics-informed learning has emerged as a strategy for incorporating domain knowledge into neural network training and architecture. Raissi et al. introduced Physics-Informed Neural Networks (PINNs) that embed governing equations as soft constraints in the loss function, enabling networks to respect physical laws even with limited training data. For optimization problems, the KKT conditions provide analogous structural constraints that characterize optimal solutions. Recent work has explored encoding KKT residuals as regularization terms to improve solution quality and generalization. However, soft penalty approaches cannot guarantee strict constraint satisfaction—a critical requirement for safety-assured robot control.

## 1.2 Contributions

In this paper, we propose PDPL-Net (Primal-Dual Proximal Learning Network), a neural network architecture for real-time point cloud perception in MPC-based robot navigation that achieves both computational efficiency and strict constraint satisfaction. Our key insight is that the dual feasibility constraints—which must be satisfied for valid distance computation—can be enforced through explicit geometric projection layers embedded within the network architecture, rather than through soft penalties or post-hoc correction. By combining PDHG algorithm unrolling with hard projection and KKT-regularized training, PDPL-Net learns to produce near-optimal dual variables that are guaranteed feasible by construction.

The contributions of this work are summarized as follows:

1. **PDHG-Unrolled Architecture with Hard Projection**: We propose a neural network architecture that unrolls the Primal-Dual Hybrid Gradient (PDHG) algorithm into trainable layers, augmented with a parameter-free hard projection layer that explicitly enforces dual feasibility constraints $\mu \geq 0$ and $\|\mathbf{G}^\top \mu\|_2 \leq 1$. This architectural design guarantees 100% constraint satisfaction regardless of input distribution.

2. **Learnable Proximal Operators for Accelerated Convergence**: We introduce learnable residual modules within the PDHG unrolling that act as data-driven proximal operators, enabling convergence to near-optimal solutions in as few as $J=1$–$2$ layers. Theoretical analysis shows that these learned operators approximate optimal preconditioning, compressing iteration complexity from $O(1/\epsilon)$ to $O(1)$.

3. **KKT Residual Regularization Training Strategy**: We propose a physics-informed training loss that incorporates primal feasibility, dual feasibility, and complementary slackness residuals derived from KKT conditions. This regularization improves generalization to out-of-distribution scenarios by encoding the mathematical structure of the optimization problem.

4. **Comprehensive Experimental Validation**: We establish a benchmark comprising 12 representative baseline methods spanning traditional optimization, black-box neural networks, algorithm unrolling, and differentiable optimization. Experiments demonstrate that PDPL-Net achieves 954× speedup over exact solvers while maintaining comparable accuracy (MSE $\sim 10^{-5}$), and improves constraint satisfaction rate from 0–88% (baselines) to 100%. Closed-loop MPC navigation experiments validate that the improved front-end translates to better path quality and computational efficiency in the complete navigation pipeline.

## 1.3 Paper Organization

The remainder of this paper is organized as follows. Section 2 formulates the mobile robot navigation problem, introduces the biconvex dual reformulation of point-level collision constraints, and describes the MPC optimization framework. Section 3 presents the PDPL-Net architecture in detail, including the feature encoder, PDHG unrolling layers, and hard projection mechanism. Section 4 describes the training strategy, including synthetic data generation, loss function design, and training configuration. Section 5 presents comprehensive experimental results comparing PDPL-Net against baseline methods, ablation studies validating each component, and closed-loop navigation experiments demonstrating end-to-end performance. Section 6 provides theoretical analysis of convergence properties and constraint guarantees. Section 7 discusses insights, limitations, and future directions. Section 8 concludes the paper.

