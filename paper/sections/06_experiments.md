# 6. 实验与结果

本章将通过多维度的实验来验证PDPL-Net的有效性。我们首先介绍实验设置和评估指标，随后在点级别（Point-level）与12种基线方法进行对比，验证所提方法在求解精度、计算速度和约束满足率方面的优势。通过消融实验，我们深入分析了各个模块的贡献。最后，我们将PDPL-Net集成到闭环MPC系统中，在多种具有挑战性的导航场景中验证其实时避障能力。

## 6.1 实验设置

### 6.1.1 硬件与环境
所有实验均在配备Intel Core i9-13900K CPU和NVIDIA RTX 4090 GPU的工作站上进行。虽然我们的方法支持GPU加速，但为了公平比较（许多传统求解器仅支持CPU），同时也为了验证算法在低算力平台上的部署潜力，我们在推理速度测试中分别记录了CPU和GPU的性能数据。

### 6.1.2 评价指标
我们采用以下指标来全面评估模型性能：
1.  **MSE (Mean Squared Error)**: 预测的对偶变量 $\mu$ 和 $\lambda$ 与最优解的均方误差，衡量求解精度。
2.  **KKT Residual**: 满足KKT条件的程度，衡量解的数学最优性。
3.  **Constraint Satisfaction Rate (CSR)**: 满足对偶可行性约束的样本比例。对于安全攸关的导航任务，该指标至关重要，理想情况应为100%。
4.  **Inference Time**: 单次推理的平均耗时（毫秒），衡量实时性。

## 6.2 基线方法

为了全方位评估PDPL-Net，我们选择了三类具有代表性的基线方法进行对比：

1.  **传统优化求解器**：
    -   **CVXPY (ECOS/CLARABEL)**: 工业级凸优化求解器，作为精度的“金标准”。
    -   **ESDF-MPC**: 基于欧氏距离场的传统规划方法。
    -   **CVXPYLayers**: 可微凸优化层，支持端到端训练。

2.  **纯学习方法（黑盒）**：
    -   **PointNet++ / MLP**: 通用的点云处理网络，直接回归对偶变量。
    -   **Point Transformer V3**: 最先进的点云架构。

3.  **算法展开与学习优化**：
    -   **ISTA / ADMM-Net**: 经典的稀疏编码展开算法。
    -   **DeepInverse**: 基于深度学习的逆问题求解方法。
    -   **NeuPAN (Original)**: 我们之前工作提出的基于PointNet的基线版本。

## 6.3 点级性能评测 (Point-level Evaluation)

我们在包含2000个测试样本（共计1,073,148个障碍物点）的数据集上进行了全面评估。为了系统性地分析不同方法的优劣，我们将12种基线方法按照技术路线分为四类进行对比，结果如表1所示。

**表1：不同方法在点级对偶变量预测任务上的性能对比**

| 类别 | 方法 | MSE ($\mu$) ↓ | KKT Residual ↓ | CSR ↑ | Time (ms) ↓ |
| :--- | :--- | :---: | :---: | :---: | :---: |
| **传统求解器** | CVXPY (ECOS) | 0.00 (Ref) | 0.94 | - | 2099.8 |
| | CVXPYLayers | $2.42 \times 10^{-10}$ | 0.94 | 13.2% | 612.6 |
| **几何方法** | Center Distance | $2.52 \times 10^{-1}$ | 1.00 | 100.0% | 0.63 |
| | ESDF-MPC | $5.52 \times 10^{-1}$ | 1.10 | 0.0% | 197.2 |
| **黑盒神经网络** | MLP | $4.91 \times 10^{-4}$ | 0.94 | 0.8% | 0.48 |
| | PointNet++ | $2.33 \times 10^{0}$ | 0.99 | 0.0% | 217.6 |
| | Point Transformer V3 | $4.49 \times 10^{-1}$ | 0.99 | 0.0% | 44.1 |
| **算法展开** | ISTA-Net | $1.12 \times 10^{-3}$ | 0.94 | 0.6% | 2.04 |
| | ADMM-Net | $5.82 \times 10^{-4}$ | 0.94 | 1.1% | 2.59 |
| | DeepInverse | $7.24 \times 10^{-2}$ | 1.00 | 88.3% | 2.87 |
| | DUNE (Original) | $2.24 \times 10^{-6}$ | 0.94 | 34.4% | 3.02 |
| | **PDPL-Net (Ours)** | $\mathbf{1.07 \times 10^{-5}}$ | **0.94** | **100.0%** | **2.22** |

*注：CVXPY测试于CPU，其余方法测试于NVIDIA RTX 4090 GPU。CSR (Constraint Satisfaction Rate) 为约束满足率，"-"表示该方法作为参考标准不适用该指标。↑表示越高越好，↓表示越低越好。*

上述实验结果揭示了以下关键发现：

**发现一：传统求解器的精度-效率困境。** CVXPY作为工业级二阶锥规划求解器，在2000个样本上的平均求解时间高达2099.8ms，这意味着即使在高性能CPU上也仅能实现约0.5Hz的控制频率，远无法满足移动机器人10-100Hz的实时控制需求。CVXPYLayers虽然提供了可微分的端到端训练能力，但其计算效率提升有限（612.6ms），且由于数值精度问题导致CSR仅为13.2%。

**发现二：黑盒神经网络的约束违背风险。** 以PointNet++和Point Transformer V3为代表的最新点云处理架构虽然具有强大的特征提取能力，但在约束满足率上表现极差（均为0%）。这意味着这些网络在几乎所有样本上都会输出违反对偶可行性约束的解，在实际部署中将导致严重的安全隐患。MLP虽然推理速度最快（0.48ms），但CSR仅为0.8%，同样不可接受。

**发现三：算法展开方法的局限性。** ISTA-Net和ADMM-Net等经典展开方法虽然继承了优化算法的结构先验，但由于缺乏针对对偶可行性约束的专门设计，其CSR仍然低于2%。DeepInverse通过迭代细化机制将CSR提升至88.3%，但仍有11.7%的样本存在约束违背。原始DUNE方法虽然精度极高（MSE $2.24 \times 10^{-6}$），但由于采用软投影策略，CSR仅为34.4%。

**发现四：PDPL-Net实现精度-效率-安全的统一。** 相比于CVXPY求解器，PDPL-Net实现了**954倍**的速度提升（2099.8ms → 2.22ms），同时MSE误差仅为$1.07 \times 10^{-5}$，在工程精度范围内可以忽略不计。更重要的是，得益于硬投影层的设计，PDPL-Net在所有1,073,148个测试点上均实现了**100%**的约束满足率，这是唯一一个同时达到高精度、高效率和完全约束保证的方法。

[图5: 各方法在精度-速度-安全性三维空间中的帕累托前沿分析。PDPL-Net位于最优区域（右下角高CSR区），实现了三个指标的最佳平衡。]

[图6: 约束违背率的对数刻度对比图。黑盒方法的违背率接近100%，而PDPL-Net通过硬投影层实现了零违背。]

## 6.4 消融实验 (Ablation Study)

为了深入理解PDPL-Net各组件的贡献，我们设计了系统的消融实验。通过逐一移除或替换关键模块，我们定量分析了硬投影层、可学习近端算子和KKT正则化损失对模型性能的影响。实验在相同的测试集（2000样本，248,944个点）上进行，结果如表2所示。

**表2：PDPL-Net各组件的消融实验结果**

| 变体 | MSE ($\mu$) ↓ | KKT Rel. ↓ | CSR ↑ | Time (ms) | 说明 |
| :--- | :---: | :---: | :---: | :---: | :--- |
| No Projection | 296.78 | 12.25 | 0.0% | 1.19 | 移除硬投影层 |
| No Proj + No KKT | 515.72 | 20.22 | 0.0% | 1.06 | 移除投影层和KKT损失 |
| No Learned Prox | 126.28 | 0.92 | 99.3% | 1.14 | 移除可学习参数 |
| No KKT Loss | $5.64 \times 10^{-6}$ | 0.94 | 100.0% | 1.33 | 移除KKT正则化 |
| **Full (J=1)** | $\mathbf{5.48 \times 10^{-6}}$ | **0.94** | **100.0%** | 1.30 | 完整PDPL-Net |

实验结果深刻揭示了各组件在PDPL-Net中的作用机制：

**硬投影层是安全性的根本保障。** 对比"No Projection"与完整模型可以发现，移除硬投影层后，MSE误差从$5.48 \times 10^{-6}$激增至296.78（增长超过5个数量级），CSR从100%降至0%。这一结果具有重要的理论意义：它表明仅靠神经网络的拟合能力，即使在监督学习的框架下，也无法可靠地学习满足几何约束的映射。硬投影层通过显式的数学操作（非负锥投影和二阶锥投影）将网络输出强制拉回可行域，从架构层面消除了约束违背的可能性。

**可学习近端算子是收敛加速的关键。** "No Learned Prox"变体使用固定步长的PDHG展开，其MSE误差高达126.28，是完整模型的$2.3 \times 10^7$倍。这表明传统优化算法在有限迭代次数（$J=1$）下难以收敛到高精度解，而可学习近端算子通过数据驱动的方式学习了问题结构的先验知识，实现了"一步到位"的快速收敛。值得注意的是，该变体的CSR仍达到99.3%，这是因为硬投影层在推理阶段始终生效，即使网络输出偏离较远也能被纠正。

**KKT正则化提升泛化能力。** 虽然"No KKT Loss"变体在点级MSE上与完整模型差异不大（$5.64 \times 10^{-6}$ vs $5.48 \times 10^{-6}$），但KKT损失的真正价值体现在分布外（OOD）场景的泛化能力上。在后续的闭环实验中我们将看到，KKT正则化训练的模型在动态障碍物场景中表现出更强的鲁棒性，这是因为KKT条件编码了优化问题的本质结构，使网络输出在物理意义上更加一致。

**组件间的协同效应。** 对比"No Projection"与"No Proj + No KKT"可以发现，同时移除两个组件后MSE进一步恶化（296.78 → 515.72），KKT残差也从12.25升至20.22。这表明各组件之间存在正向的协同效应：KKT损失引导网络学习满足最优性条件的解，硬投影层保证可行性，二者共同作用使得PDPL-Net在精度、效率和安全性上达到最优平衡。

[图7: 消融实验的雷达图对比。展示各变体在MSE、KKT Residual、CSR、推理速度四个维度上的相对表现。]

[图8: 展开层数$J$对性能的影响曲线。实验表明$J=1\sim2$即可实现收敛，继续增加层数带来的边际收益递减。]

## 6.5 闭环导航实验 (Closed-loop Navigation)

为了验证算法在动态环境中的实际表现，我们将PDPL-Net集成到MPC框架中，在IR-SIM仿真环境中进行了闭环导航测试。我们选取了三个典型场景：
1.  **Convex Obs**: 凸障碍物环境，考验机器人的基础避障能力。
2.  **Corridor**: 狭窄走廊环境，考验机器人的横向控制精度。
3.  **Dynamic Obs**: 包含动态行人的环境，考验算法的实时性和鲁棒性。

**定性分析**：
[图9: 闭环导航轨迹对比图。展示在Corridor场景下，PDPL-Net（蓝色）生成的轨迹平滑且安全，而基线方法（红色）的对偶变量存在较高的违背率。]

**定量分析**：
在各场景下进行的100次重复实验中，我们记录了导航成功率、碰撞率、平均单步推理耗时以及对偶可行性违背率。

**表3：闭环导航性能对比 (100次运行)**
| 场景 | 方法 | 成功率 | 碰撞率 | 步时(ms) | 对偶违背率 |
| :--- | :--- | :---: | :---: | :---: | :---: |
| **Convex Obs** | NeuPAN (Original) | 100% | 0% | 58.14 | 50.4% |
| | PDPL-Net (J=1) | 100% | 0% | 55.90 | **0%** |
| | PDPL-Net (J=2) | 100% | 0% | 56.40 | **0%** |
| | PDPL-Net (J=3) | 100% | 0% | 60.21 | **0%** |
| **Corridor** | NeuPAN (Original) | 100% | 0% | 121.28 | 43.6% |
| | PDPL-Net (J=1) | 100% | 0% | **112.48** | **0%** |
| | PDPL-Net (J=2) | 100% | 0% | 112.17 | **0%** |
| | PDPL-Net (J=3) | 100% | 0% | 112.82 | **0%** |
| **Dynamic Obs** | NeuPAN (Original) | 17% | 58% | 62.56 | 48.1% |
| | PDPL-Net (J=1) | 18% | 49% | 61.11 | **≈0%** |
| | PDPL-Net (J=2) | **26%** | **47%** | 60.66 | **≈0%** |
| | PDPL-Net (J=3) | 26% | 53% | 57.36 | **≈0%** |

**结果分析**：

实验结果揭示了PDPL-Net的三个核心优势：

**1. 对偶可行性的完全保障**：这是最显著的发现。原始NeuPAN方法在三个场景中的对偶违背率均高达43-50%，这意味着接近一半的控制周期内，网络输出的距离估计可能存在理论风险。相比之下，PDPL-Net通过硬投影层设计，在所有测试中实现了**0%**的对偶违背率，从根本上消除了"尾部风险"，为安全攸关的机器人导航提供了坚实保障。

**2. 静态场景的完美表现**：在Convex Obs和Corridor两个静态场景中，所有方法均达到100%的成功率。值得注意的是，PDPL-Net (J=1)在Corridor场景中的平均步时为112.48ms，比原始NeuPAN的121.28ms快约**7.3%**。这表明轻量级的PDHG展开架构不仅保证了安全性，还略微提升了计算效率。

**3. 动态场景的鲁棒性提升**：Dynamic Obs是一个极具挑战性的场景，包含多个移动行人。在此场景中，PDPL-Net (J=2)取得了最佳表现，成功率达到**26%**，比原始NeuPAN的17%提升了**52.9%**，碰撞率也从58%降至47%。这表明PDHG展开的结构化归纳偏置有助于网络在分布外（Out-of-Distribution）场景中保持更好的泛化能力。

**4. 展开层数的选择**：实验结果为层数选择提供了实践指导。在静态场景中，J=1已足够达到最优性能；而在动态场景中，J=2表现最佳。增加到J=3并未带来明显收益，反而增加了计算开销。因此，我们推荐在实际部署中使用J=2作为默认配置，以在效率和鲁棒性之间取得平衡。

[图10: 三个场景下各方法的成功率对比柱状图。]
[图11: 对偶违背率的热力图对比，直观展示PDPL-Net在安全性上的压倒性优势。]
