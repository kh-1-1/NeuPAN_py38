# 5. 实验与结果

本章通过多维度的实验验证PDPL-Net的有效性。我们首先介绍实验设置和评估指标，随后在点级别与12种基线方法进行对比，验证所提方法在求解精度、计算速度和约束满足率方面的优势。通过消融实验，我们深入分析各个模块的贡献。最后，我们将PDPL-Net集成到闭环MPC系统中，验证改进的前端模块如何转化为后端规划的实际收益。

## 5.1 实验设置

### 5.1.1 数据集与硬件平台

点级评估实验在包含2,000个测试样本的数据集上进行，这些样本独立于训练集生成，覆盖了机器人周围$[-10m, 10m]^2$范围内的障碍物点分布。每个样本包含一个障碍物点及其对应的精确对偶变量标签（由ECOS求解器计算）。闭环导航实验在IR-SIM仿真环境中进行，该环境提供了阿克曼转向机器人的物理仿真，支持激光雷达点云感知和实时MPC控制。

所有实验均在配备Intel Core i9-13900K CPU和NVIDIA RTX 4090 GPU的工作站上进行。为了公平比较（许多传统求解器仅支持CPU），我们在推理速度测试中分别记录了CPU和GPU的性能数据。PDPL-Net及所有神经网络基线方法使用PyTorch 2.0实现，传统优化方法使用CVXPY调用ECOS或CLARABEL求解器。

### 5.1.2 评价指标

我们采用以下指标全面评估模型性能：

**对偶变量精度**。均方误差（MSE）衡量预测的对偶变量$\mu$与最优解$\mu^*$之间的偏差：$\text{MSE} = \frac{1}{N}\sum_{i=1}^N \|\mu_i - \mu^*_i\|_2^2$。MSE越低表示预测越接近最优解。

**KKT残差**。衡量预测解满足KKT最优性条件的程度，计算方法见第4.2.2节。KKT残差越低表示解的数学最优性越好。

**约束满足率（CSR）**。满足对偶可行性约束$\mu \geq 0$且$\|\mathbf{G}^\top \mu\|_2 \leq 1$的样本比例。对于安全攸关的导航任务，该指标至关重要，理想情况应为100%。

**推理时间**。单次推理的平均耗时（毫秒），衡量实时性。对于MPC应用，推理时间需要控制在10ms以内以满足100Hz的控制频率要求。

**对偶违背率**。约束满足率的补集，即$\mu < 0$或$\|\mathbf{G}^\top \mu\|_2 > 1$的样本比例。该指标直接反映了方法的安全风险。

### 5.1.3 基线方法

为了全方位评估PDPL-Net，我们选择了四类共12种代表性基线方法：

**传统优化求解器**（3种）：
- **CVXPY (ECOS)**：工业级凸优化求解器，作为精度的"金标准"参考
- **CVXPY (CLARABEL)**：新一代Rust实现的锥规划求解器
- **CVXPYLayers**：可微分凸优化层，支持端到端训练

**黑盒神经网络**（3种）：
- **MLP**：标准多层感知机，直接回归对偶变量
- **PointNet++**：层次化点云特征学习网络
- **Point Transformer V3**：2024年CVPR最新的点云Transformer架构

**算法展开方法**（4种）：
- **ISTA-Net**：迭代软阈值算法展开网络
- **ADMM-Net**：交替方向乘子法展开网络
- **DeepInverse**：基于深度学习的逆问题求解框架
- **DUNE (NeuPAN原始)**：NeuPAN中的PointNet基线前端

**几何方法**（2种）：
- **Center Distance**：中心点距离近似方法
- **ESDF-MPC**：基于欧几里得符号距离场的传统方法

## 5.2 点级性能对比

表3展示了所有方法在点级对偶变量预测任务上的性能对比。实验在2,000个测试样本上进行，每个样本包含数百个障碍物点，共计约100万个测试点。

**表3：点级对偶变量预测性能对比**

| 类别 | 方法 | MSE ($\mu$) ↓ | KKT残差 ↓ | CSR ↑ | 时间 (ms) ↓ |
|:-----|:-----|:-------------:|:---------:|:-----:|:-----------:|
| **传统求解器** | CVXPY (ECOS) | 0.00 (参考) | 0.94 | — | 2099.8 |
| | CVXPYLayers | $2.42 \times 10^{-10}$ | 0.94 | 13.2% | 612.6 |
| **几何方法** | Center Distance | $2.52 \times 10^{-1}$ | 1.00 | 100.0% | 0.63 |
| | ESDF-MPC | $5.52 \times 10^{-1}$ | 1.10 | 0.0% | 197.2 |
| **黑盒网络** | MLP | $4.91 \times 10^{-4}$ | 0.94 | 0.8% | 0.48 |
| | PointNet++ | $2.33 \times 10^{0}$ | 0.99 | 0.0% | 217.6 |
| | Point Transformer V3 | $4.49 \times 10^{-1}$ | 0.99 | 0.0% | 44.1 |
| **算法展开** | ISTA-Net | $1.12 \times 10^{-3}$ | 0.94 | 0.6% | 2.04 |
| | ADMM-Net | $5.82 \times 10^{-4}$ | 0.94 | 1.1% | 2.59 |
| | DeepInverse | $7.24 \times 10^{-2}$ | 1.00 | 88.3% | 2.87 |
| | DUNE (Original) | $2.24 \times 10^{-6}$ | 0.94 | 34.4% | 3.02 |
| | **PDPL-Net (Ours)** | $\mathbf{1.07 \times 10^{-5}}$ | **0.94** | **100.0%** | **2.22** |

*注：CVXPY测试于CPU，其余方法测试于GPU。CSR为约束满足率，"—"表示参考标准不适用该指标。*

上述实验结果揭示了以下关键发现：

**发现一：传统求解器的精度-效率困境**。CVXPY作为工业级二阶锥规划求解器，在2,000个样本上的平均求解时间高达2099.8毫秒。这意味着即使在高性能CPU上也仅能实现约0.5Hz的控制频率，远无法满足移动机器人10–100Hz的实时控制需求。CVXPYLayers虽然提供了可微分的端到端训练能力，但其计算效率提升有限（612.6ms），且由于数值精度问题导致CSR仅为13.2%。传统求解器在需要处理大规模点云的实时应用中面临根本性的计算瓶颈。

**发现二：黑盒神经网络的约束违背风险**。以PointNet++和Point Transformer V3为代表的最新点云处理架构虽然具有强大的特征提取能力，但在约束满足率上表现极差（均为0%）。这意味着这些网络在几乎所有样本上都会输出违反对偶可行性约束的解。MLP虽然推理速度最快（0.48ms），但CSR仅为0.8%。这些结果证实了我们在第3.4节的分析：仅靠神经网络的拟合能力无法可靠地学习满足几何约束的映射，约束可行域的边界在高维空间中是测度为零的集合。

**发现三：算法展开方法的局限性**。ISTA-Net和ADMM-Net等经典展开方法虽然继承了优化算法的结构先验，但由于缺乏针对对偶可行性约束的专门设计，其CSR仍然低于2%。DeepInverse通过迭代细化机制将CSR提升至88.3%，但仍有11.7%的样本存在约束违背。原始DUNE方法虽然精度极高（MSE $2.24 \times 10^{-6}$），但由于采用软投影策略，CSR仅为34.4%——这意味着超过三分之一的预测结果需要事后修正。

**发现四：PDPL-Net实现精度-效率-安全的统一**。相比于CVXPY求解器，PDPL-Net实现了**954倍**的速度提升（2099.8ms → 2.22ms），同时MSE误差仅为$1.07 \times 10^{-5}$，在工程精度范围内可以忽略不计。更重要的是，得益于硬投影层的架构设计，PDPL-Net在所有测试点上均实现了**100%**的约束满足率。这是唯一一个同时达到高精度、高效率和完全约束保证的方法，证明了"结构化展开+硬投影保障"设计范式的有效性。

## 5.3 消融实验

为了深入理解PDPL-Net各组件的贡献，我们设计了系统的消融实验。通过逐一移除或替换关键模块，定量分析硬投影层、可学习近端算子和KKT正则化损失对模型性能的影响。

**表4：PDPL-Net各组件的消融实验结果**

| 变体 | MSE ($\mu$) ↓ | KKT残差 ↓ | CSR ↑ | 时间 (ms) |
|:-----|:-------------:|:---------:|:-----:|:---------:|
| 无硬投影层 | 296.78 | 12.25 | 0.0% | 1.19 |
| 无投影 + 无KKT | 515.72 | 20.22 | 0.0% | 1.06 |
| 无可学习近端算子 | 126.28 | 0.92 | 99.3% | 1.14 |
| 无KKT正则化 | $5.64 \times 10^{-6}$ | 0.94 | 100.0% | 1.33 |
| **完整版 (J=1)** | $\mathbf{5.48 \times 10^{-6}}$ | **0.94** | **100.0%** | 1.30 |

消融实验结果深刻揭示了各组件在PDPL-Net中的作用机制：

**硬投影层是安全性的根本保障**。对比"无硬投影层"与完整模型可以发现，移除硬投影层后，MSE误差从$5.48 \times 10^{-6}$激增至296.78（增长超过5个数量级），CSR从100%降至0%。这一结果具有重要的理论意义：它表明仅靠神经网络的拟合能力，即使在监督学习的框架下，也无法可靠地学习满足几何约束的映射。硬投影层通过显式的数学操作将网络输出强制拉回可行域，从架构层面消除了约束违背的可能性。

**可学习近端算子是收敛加速的关键**。"无可学习近端算子"变体使用固定步长的PDHG展开，其MSE误差高达126.28，是完整模型的$2.3 \times 10^7$倍。这表明传统优化算法在有限迭代次数（$J=1$）下难以收敛到高精度解，而可学习近端算子通过数据驱动的方式学习了问题结构的先验知识，实现了"一步到位"的快速收敛。值得注意的是，该变体的CSR仍达到99.3%，这是因为硬投影层在推理阶段始终生效。

**KKT正则化提升泛化能力**。虽然"无KKT正则化"变体在点级MSE上与完整模型差异不大（$5.64 \times 10^{-6}$ vs $5.48 \times 10^{-6}$），但KKT损失的真正价值体现在分布外场景的泛化能力上。后续闭环实验将展示，KKT正则化训练的模型在动态障碍物场景中表现出更强的鲁棒性。

## 5.4 闭环导航实验

感知模块的最终价值体现在完整导航流程中的实际表现。虽然点级指标（如MSE和CSR）刻画了对偶变量预测的质量，但闭环实验揭示了前端改进如何转化为后端规划的可观测收益。本节将PDPL-Net作为前端感知模块集成到NeuPAN MPC框架中，在多个典型场景中进行评估。

关键地，我们选择的测试场景是所有方法都能成功通过的场景。这一设计使我们能够聚焦于**前端改进在后端展现的优势**——对偶可行性、计算效率和路径质量——而非简单比较成功率。

### 5.4.1 实验配置

闭环实验在IR-SIM仿真环境中进行，机器人采用阿克曼转向模型，轴距3.0米，最大转向角1.0弧度。我们选取两个代表性场景：

- **凸障碍物场景（convex_obs）**：包含若干凸多边形障碍物，机器人需要规划平滑的绕行轨迹。该场景考验距离估计的精度和梯度信息的质量。

- **狭窄走廊场景（corridor）**：机器人需穿越狭窄通道，对横向控制精度要求极高。该场景几何约束严格，各方法的轨迹差异有限，用于验证PDPL-Net不会引入性能退化。

对比方法包括：
- **Baseline (DUNE)**：NeuPAN原始的PointNet前端
- **PDPL-Net (J=1)**：单层PDHG展开
- **PDPL-Net (J=2)**：两层PDHG展开
- **PDPL-Net (J=3)**：三层PDHG展开

### 5.4.2 对偶可行性：从概率性到确定性

闭环运行中最显著的优势是**对偶可行性违背的完全消除**。表5展示了导航过程中所有MPC步骤的对偶违背统计。

**表5：闭环导航中的对偶可行性统计**

| 方法 | J | 对偶违背率 ↓ | P95范数 | 解释 |
|:-----|:-:|:-----------:|:-------:|:-----|
| Baseline (DUNE) | — | 43–50% | > 1.007 | 近半数推理步骤产生不可行对偶变量 |
| **PDPL-Net** | J=1 | **0.0%** | **1.000** | 完美约束满足 |
| **PDPL-Net** | J=2 | **0.0%** | **1.000** | 完美约束满足 |
| **PDPL-Net** | J=3 | **0.0%** | **1.000** | 完美约束满足 |

Baseline的DUNE模块在导航过程中约43–50%的推理调用违背对偶可行性约束，表现为$\|\mathbf{G}^\top \mu\|_2 > 1$。虽然NeuPAN在NRMP层之前应用硬投影进行修正，但这种事后修正有两个负面影响：（1）修正后的解可能与网络预期输出偏差较大，导致传递给优化器的梯度信息质量下降；（2）训练（无投影）与推理（有投影）之间的不一致可能引发分布偏移效应。

相比之下，PDPL-Net的对偶违背率精确为0%，无论展开层数$J$取何值。这种结构性保证消除了事后修正的需求，确保优化器在每个控制步骤都接收到高质量、几何有效的距离信息。从安全角度看，这将对偶可行性从"概率性保证"提升到了"确定性保证"——对于安全攸关的机器人应用，这一质变具有根本性意义。

### 5.4.3 计算效率

除约束满足外，PDPL-Net在闭环运行中也展现了计算效率优势。表6展示了各方法在两个场景中的单步计算时间。

**表6：闭环导航单步计算时间 (ms)**

| 场景 | Baseline | J=1 | J=2 | J=3 | 加速比 (J=1) |
|:-----|:--------:|:---:|:---:|:---:|:-----------:|
| convex_obs | 56.38 | **52.48** | 56.10 | 58.90 | +7.0% |
| corridor | 115.60 | **106.63** | 105.78 | 106.69 | +7.8% |

PDPL-Net (J=1)实现了最快的计算速度，比Baseline快约7–8%。这一加速源于PDPL-Net相比Baseline的PointNet特征提取更为精简的架构设计。虽然增加展开层数（J=2, J=3）会略微增加计算时间，但所有PDPL-Net变体仍快于或持平于Baseline。

需要指出的是，单步计算时间主要由后端NRMP优化层主导，前端感知模块仅占总时间的10–15%。因此，前端架构改进带来的加速在整体流程中表现为较温和的百分比提升。然而，这种一致性的效率优势在长时间导航任务中会累积产生显著影响。

### 5.4.4 路径质量

改进的前端质量转化为可观测的轨迹优化收益。表7展示了convex_obs场景中的路径质量指标，该场景的障碍物几何为规划质量差异提供了充分空间。

**表7：convex_obs场景路径质量指标**

| 方法 | J | 到达步数 ↓ | 路径长度 (m) ↓ | 最大速度 (m/s) |
|:-----|:-:|:---------:|:-------------:|:-------------:|
| Baseline | — | 146 | 53.43 | 5.44 |
| PDPL-Net | J=1 | 172 | 53.63 | 5.39 |
| PDPL-Net | J=2 | 145 | 53.42 | 5.44 |
| **PDPL-Net** | **J=3** | **138** | **53.33** | 5.40 |

结果揭示了一个有趣的趋势：随着展开层数$J$增加，路径质量渐进提升。PDPL-Net (J=3)取得了最少的到达步数（138步 vs Baseline的146步，减少5.5%）和最短的路径长度（53.33m vs 53.43m）。这一改进表明，额外的展开层产生了更高质量的对偶变量估计，进而为优化器提供了更精确的距离梯度信息。凭借更好的梯度，MPC能够生成更高效地绕过障碍物的轨迹。

J=1变体表现出略微保守的行为，需要比Baseline更多的步数。这表明单层展开虽然足以保证约束满足，但可能未完全捕获最优解结构。J=2变体与Baseline性能接近，而J=3超越了它。这一渐进趋势验证了算法展开的设计原理：每增加一层都使解更接近最优。

对于corridor场景，所有方法表现出几乎相同的路径质量指标（179–181步），表明这一几何受限环境留给轨迹变化的空间有限。corridor场景因此确认了PDPL-Net即使在Baseline已接近几何最优的情况下也不会引入性能退化。

### 5.4.5 闭环优势总结

闭环导航实验证明了PDPL-Net作为前端感知模块的三个核心优势：

**1. 对偶可行性的确定性保证**。结构化的硬投影层完全消除了约束违背（0% vs 43–50%），在每个控制步骤为后端优化器提供几何有效的距离信息。这一保证对于安全攸关的应用尤为重要，其理论正确性与经验性能同等关键。

**2. 计算效率提升**。精简的PDPL-Net架构实现了比Baseline快7–8%的单步计算，J=1变体效率最高。虽然百分比提升看似温和，但在数千个控制步骤的实际导航任务中会累积产生显著影响。

**3. 深层展开带来更优路径质量**。增加展开层数$J$渐进提升路径质量，J=3在convex_obs场景中比Baseline减少5.5%的步数。这验证了算法展开能够随层数增加产生更优解，且改进的前端精度能够转化为可观测的机器人行为收益。

综合考虑，我们推荐**J=2或J=3**作为实际部署的默认配置。J=2在各场景中提供稳定性能且计算开销最小；J=3在轨迹优化性至关重要的应用中提供最佳路径质量。

