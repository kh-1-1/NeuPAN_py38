# NeuPAN 模型训练结果对比分析报告

**生成时间**: 自动生成

**分析范围**: 基线模型 (example/model) + 新训练模型 (example/dune_train/model)

---

## 1. 模型清单总览

### 1.1 Acker 机器人模型

| 模型名称 | Projection | KKT | PDHG-J | SE(2) | 训练轮数 | 状态 |
|---------|-----------|-----|--------|-------|---------|------|
| acker_learned_prox_kkt_robot | learned | ✓ | 0 | ✗ | 2500/2500 | ✅ 完成 |
| acker_learned_prox_kkt_robot_1_failed | learned | ✓ | 0 | ✗ | 2500/2500 | ❌ 失败 |
| acker_learned_prox_kkt_tuned_robot | learned | ✓ | 0 | ✗ | 1500/1500 | ✅ 完成 |
| acker_learned_prox_kkt_tuned_robot_1 | learned | ✓ | 0 | ✗ | 1500/1500 | ✅ 完成 |
| acker_learned_prox_kkt_tuned_robot_2 | learned | ✓ | 0 | ✗ | 2500/2500 | ✅ 完成 |
| acker_learned_prox_pdhg-1_robot | learned | ✗ | 1 | ✗ | N/A/N/A | ✅ 完成 |
| acker_learned_prox_robot | learned | ✗ | 0 | ✗ | 2500/2500 | ✅ 完成 |
| acker_robot_default | hard | ✗ | 0 | ✗ | 5000/5000 | ✅ 基线 |
| acker_se2_learned_pdhg-1_kkt_robot | learned | ✓ | 1 | ✓ | N/A/N/A | ✅ 完成 |

### 1.2 Diff 机器人模型

| 模型名称 | Projection | KKT | PDHG-J | SE(2) | 训练轮数 | 状态 |
|---------|-----------|-----|--------|-------|---------|------|
| diff_learned_prox__pdhg-1_robot | learned | ✗ | 1 | ✗ | 2500/2500 | ✅ 完成 |
| diff_learned_prox_kkt_robot | learned | ✓ | 0 | ✗ | 1000/1000 | ✅ 完成 |
| diff_learned_prox_kkt_tuned_robot | learned | ✓ | 0 | ✗ | 1000/1000 | ✅ 完成 |
| diff_learned_prox_kkt_tuned_robot_1 | learned | ✓ | 0 | ✗ | 1000/1000 | ✅ 完成 |
| diff_learned_prox_kkt_tuned_robot_2 | learned | ✓ | 0 | ✗ | 2500/2500 | ✅ 完成 |
| diff_learned_prox_robot | learned | ✗ | 0 | ✗ | 2500/2500 | ✅ 完成 |
| diff_robot_default | hard | ✗ | 0 | ✗ | 5000/5000 | ✅ 基线 |
| diff_se2_learned_pdhg-1_kkt_robot | learned | ✓ | 1 | ✓ | 5000/5000 | ✅ 完成 |

---

## 2. 基线模型性能基准

### 2.1 Acker 基线 (Hard Projection, 无 KKT/PDHG/SE2)

- **训练 Mu Loss**: 1.32e-06
- **验证 Mu Loss**: 2.31e-06
- **训练 Distance Loss**: 1.27e-05
- **验证 Distance Loss**: 9.40e-06
- **训练 Fa Loss**: 8.95e-06
- **验证 Fa Loss**: 3.09e-05
- **训练 Fb Loss**: 6.95e-05
- **验证 Fb Loss**: 3.00e-04
- **训练轮数**: 5000/5000
- **数据来源**: `example\model\acker_robot_default/results.txt` 第 20009 行附近

### 2.2 Diff 基线 (Hard Projection, 无 KKT/PDHG/SE2)

- **训练 Mu Loss**: 9.52e-07
- **验证 Mu Loss**: 7.71e-06
- **训练 Distance Loss**: 7.38e-06
- **验证 Distance Loss**: 6.86e-06
- **训练 Fa Loss**: 6.63e-06
- **验证 Fa Loss**: 4.99e-05
- **训练 Fb Loss**: 3.71e-05
- **验证 Fb Loss**: 6.55e-05
- **训练轮数**: 5000/5000
- **数据来源**: `example\model\diff_robot_default/results.txt` 第 20009 行附近

---

## 3. 新模型训练结果汇总

### 3.1 Acker 新训练模型性能表

| 模型名称 | Train Mu | Val Mu | Train Dist | Val Dist | Train KKT | Val KKT | 轮数 |
|---------|----------|--------|------------|----------|-----------|---------|------|
| acker_learned_prox_kkt_robot | 6.37e-07 | 8.10e-07 | 1.46e-05 | 1.48e-05 | - | - | 2500/2500 |
| acker_learned_prox_kkt_tuned_robot | 2.83e-07 | 8.24e-07 | 8.83e-06 | 6.37e-06 | - | - | 1500/1500 |
| acker_learned_prox_kkt_tuned_robot_1 | 1.56e-06 | 4.62e-06 | 6.71e-06 | 6.81e-06 | 9.38e-01 | 9.38e-01 | 1500/1500 |
| acker_learned_prox_kkt_tuned_robot_2 | 3.81e-07 | 3.39e-07 | 2.37e-06 | 1.33e-06 | 9.36e-01 | 9.36e-01 | 2500/2500 |
| acker_learned_prox_pdhg-1_robot | N/A | N/A | N/A | N/A | - | - | N/A/N/A |
| acker_learned_prox_robot | 3.43e-07 | 4.52e-06 | 3.86e-05 | 3.38e-05 | - | - | 2500/2500 |
| acker_se2_learned_pdhg-1_kkt_robot | N/A | N/A | N/A | N/A | 9.32e-01 | 9.33e-01 | N/A/N/A |

### 3.2 Diff 新训练模型性能表

| 模型名称 | Train Mu | Val Mu | Train Dist | Val Dist | Train KKT | Val KKT | 轮数 |
|---------|----------|--------|------------|----------|-----------|---------|------|
| diff_learned_prox__pdhg-1_robot | 5.25e-06 | 8.44e-06 | 3.58e-07 | 3.42e-07 | - | - | 2500/2500 |
| diff_learned_prox_kkt_robot | 1.04e-06 | 5.62e-06 | 8.74e-06 | 9.47e-06 | - | - | 1000/1000 |
| diff_learned_prox_kkt_tuned_robot | 1.65e-06 | 2.94e-06 | 8.39e-06 | 8.90e-06 | - | - | 1000/1000 |
| diff_learned_prox_kkt_tuned_robot_1 | 1.45e-06 | 7.50e-06 | 8.29e-06 | 8.69e-06 | 9.87e-01 | 9.87e-01 | 1000/1000 |
| diff_learned_prox_kkt_tuned_robot_2 | 5.36e-07 | 8.55e-07 | 1.61e-06 | 1.44e-06 | 9.37e-01 | 9.37e-01 | 2500/2500 |
| diff_learned_prox_robot | 1.87e-06 | 4.09e-06 | 1.65e-05 | 1.36e-05 | - | - | 2500/2500 |
| diff_se2_learned_pdhg-1_kkt_robot | 3.66e-06 | 9.67e-06 | 2.41e-07 | 2.36e-07 | 9.37e-01 | 9.37e-01 | 5000/5000 |

---

## 4. 模块贡献分析

### 4.1 Learned-Prox vs Hard Projection 对比

**Acker 机器人**:
- 基线 (Hard): Val Mu Loss = 2.31e-06, Val Dist Loss = 9.40e-06
- Learned-Prox: Val Mu Loss = 4.52e-06, Val Dist Loss = 3.38e-05
- **变化**: Mu Loss -95.7%, Dist Loss -259.6%
- **说明**: 单独使用 Learned-Prox 在 Acker 上表现不如基线,可能需要配合其他模块使用

**Diff 机器人**:
- 基线 (Hard): Val Mu Loss = 7.71e-06, Val Dist Loss = 6.86e-06
- Learned-Prox: Val Mu Loss = 4.09e-06, Val Dist Loss = 1.36e-05
- **改进**: Mu Loss +47.0%, Dist Loss -98.2%
- **说明**: Learned-Prox 在 Diff 上对 Mu Loss 有改进,但 Distance Loss 略有下降

### 4.2 KKT 正则化影响

**Acker 机器人** (Learned-Prox 基础上添加 KKT):
- 无 KKT: Val Mu Loss = 4.52e-06, Val Dist Loss = 3.38e-05
- 有 KKT (acker_learned_prox_kkt_robot): Val Mu Loss = 8.10e-07, Val Dist Loss = 1.48e-05
- KKT 残差: 数据未记录 (results_reg.txt 缺失)
- **改进**: Mu Loss +82.1%, Dist Loss +56.2%
- **说明**: KKT 正则化显著改善了 Acker 模型性能

**Diff 机器人** (Learned-Prox 基础上添加 KKT):
- 无 KKT: Val Mu Loss = 4.09e-06, Val Dist Loss = 1.36e-05
- 有 KKT (diff_learned_prox_kkt_robot): Val Mu Loss = 5.62e-06, Val Dist Loss = 9.47e-06
- KKT 残差: 数据未记录
- **变化**: Mu Loss -37.4%, Dist Loss +30.4%
- **说明**: KKT 对 Diff 的影响不如 Acker 明显,可能需要调整参数

### 4.3 PDHG Unroll 影响

**Acker 机器人** (Learned-Prox 基础上添加 PDHG-1):
- 无 PDHG: Val Mu Loss = 4.52e-06, Val Dist Loss = 3.38e-05
- PDHG-1 (acker_learned_prox_pdhg-1_robot): Val Mu Loss = 7.97e-03, Val Dist Loss = 3.43e+00
- **说明**: ⚠️ PDHG-1 单独使用时训练未收敛,损失值异常高,可能需要配合 KKT 或调整超参数

**Diff 机器人** (Learned-Prox 基础上添加 PDHG-1):
- 无 PDHG: Val Mu Loss = 4.09e-06, Val Dist Loss = 1.36e-05
- PDHG-1 (diff_learned_prox__pdhg-1_robot): Val Mu Loss = 8.44e-06, Val Dist Loss = 3.42e-07
- **变化**: Mu Loss -106.4%, Dist Loss +97.5%
- **说明**: PDHG-1 在 Diff 上对 Distance Loss 有显著改进,但 Mu Loss 下降

### 4.4 SE(2) Equivariant Encoding 影响

**Acker 机器人** (SE2 + Learned-Prox + PDHG-1 + KKT 组合):
- Val Mu Loss = 3.52e-03, Val Dist Loss = 1.33e+00
- KKT 残差: Train = 9.32e-01, Val = 9.33e-01
- **相比基线变化**: Mu Loss -152252.4%, Dist Loss -14051.1%
- **说明**: ⚠️ 该组合模型训练未收敛,损失值异常高,需要重新调整训练策略

**Diff 机器人** (SE2 + Learned-Prox + PDHG-1 + KKT 组合):
- Val Mu Loss = 9.67e-06, Val Dist Loss = 2.36e-07
- KKT 残差: Train = 9.37e-01, Val = 9.37e-01
- **相比基线改进**: Mu Loss -25.4%, Dist Loss +96.6%
- **说明**: SE2 组合在 Diff 上对 Distance Loss 有极大改进,但 Mu Loss 略有下降

### 4.5 调优 (Tuned) 模型分析

**Acker 最佳调优模型** (acker_learned_prox_kkt_tuned_robot_2):
- Val Mu Loss = 3.39e-07, Val Dist Loss = 1.33e-06
- KKT 残差: Train = 9.36e-01, Val = 9.36e-01
- **相比基线改进**: Mu Loss +85.3%, Dist Loss +85.9%
- **配置特点**: Learned-Prox + KKT,经过参数调优

**Diff 最佳调优模型** (diff_learned_prox_kkt_tuned_robot_2):
- Val Mu Loss = 8.55e-07, Val Dist Loss = 1.44e-06
- KKT 残差: Train = 9.37e-01, Val = 9.37e-01
- **相比基线改进**: Mu Loss +88.9%, Dist Loss +79.0%
- **配置特点**: Learned-Prox + KKT,经过参数调优

---

## 5. 最优模型推荐

### 5.1 Acker 机器人最优配置

**推荐模型**: `acker_learned_prox_kkt_tuned_robot_2`

- **配置**: Projection=learned, KKT=✓, PDHG-J=0, SE(2)=✗
- **性能**: Val Mu Loss = 3.39e-07, Val Dist Loss = 1.33e-06
- **相比基线改进**: Mu Loss +85.3%, Dist Loss +85.9%

### 5.2 Diff 机器人最优配置

**推荐模型**: `diff_learned_prox_kkt_tuned_robot_2`

- **配置**: Projection=learned, KKT=✓, PDHG-J=0, SE(2)=✗
- **性能**: Val Mu Loss = 8.55e-07, Val Dist Loss = 1.44e-06
- **相比基线改进**: Mu Loss +88.9%, Dist Loss +79.0%

---

## 6. 发现与建议

### 6.1 关键发现

1. **Learned-Prox 需要配合使用**
   - 单独使用 Learned-Prox 在 Acker 上表现不如基线
   - 在 Diff 上有一定改进,但不显著
   - **结论**: Learned-Prox 需要配合 KKT 或其他模块才能发挥最佳效果

2. **KKT 正则化是关键**
   - Learned-Prox + KKT 组合在两种机器人上均取得最佳性能
   - Acker: 相比基线改进 85%+
   - Diff: 相比基线改进 79%+
   - **结论**: KKT 正则化是性能提升的核心因素

3. **PDHG Unroll 需要谨慎使用**
   - 单独使用 PDHG-1 在 Acker 上训练未收敛 (损失值 1e-3 量级)
   - 在 Diff 上对 Distance Loss 有改进,但 Mu Loss 下降
   - 与 SE(2) + KKT 组合时在 Acker 上仍未收敛
   - **结论**: PDHG 需要更仔细的超参数调优,不建议单独使用

4. **SE(2) 等变性效果有限**
   - SE(2) + Learned-Prox + PDHG-1 + KKT 组合在 Acker 上训练失败
   - 在 Diff 上对 Distance Loss 有极大改进 (96.6%),但 Mu Loss 下降
   - **结论**: SE(2) 编码可能对特定任务有帮助,但需要更多实验验证

5. **调优 (Tuned) 模型表现最佳**
   - 经过参数调优的 Learned-Prox + KKT 模型在两种机器人上均达到最佳性能
   - Acker 最佳: `acker_learned_prox_kkt_tuned_robot_2` (Val Mu Loss 3.39e-07)
   - Diff 最佳: `diff_learned_prox_kkt_tuned_robot_2` (Val Mu Loss 8.55e-07)
   - **结论**: 超参数调优对最终性能至关重要

### 6.2 训练稳定性分析

**训练未收敛的模型**:
1. `acker_learned_prox_pdhg-1_robot`: Val Mu Loss = 7.97e-03 (正常应为 1e-6 量级)
2. `acker_se2_learned_pdhg-1_kkt_robot`: Val Mu Loss = 3.52e-03 (正常应为 1e-6 量级)

**失败模型**:
- `acker_learned_prox_kkt_robot_1_failed`: 标记为失败,原因未知

**可能的原因**:
- PDHG 展开引入的额外复杂度导致训练不稳定
- SE(2) 编码与其他模块的兼容性问题
- 学习率或其他超参数设置不当
- 训练数据或初始化问题

### 6.3 模型性能排名

**Acker 机器人** (按 Val Mu Loss 排序):
1. ✅ `acker_learned_prox_kkt_tuned_robot_2`: 3.39e-07 (最佳)
2. ✅ `acker_learned_prox_robot`: 4.52e-06
3. ✅ `acker_learned_prox_kkt_robot`: 8.10e-07
4. ✅ `acker_learned_prox_kkt_tuned_robot`: 8.24e-07
5. ⚠️ `acker_se2_learned_pdhg-1_kkt_robot`: 3.52e-03 (未收敛)
6. ⚠️ `acker_learned_prox_pdhg-1_robot`: 7.97e-03 (未收敛)

**Diff 机器人** (按 Val Mu Loss 排序):
1. ✅ `diff_learned_prox_kkt_tuned_robot_2`: 8.55e-07 (最佳)
2. ✅ `diff_learned_prox_kkt_tuned_robot`: 2.94e-06
3. ✅ `diff_learned_prox_robot`: 4.09e-06
4. ✅ `diff_learned_prox_kkt_robot`: 5.62e-06
5. ✅ `diff_learned_prox__pdhg-1_robot`: 8.44e-06
6. ✅ `diff_se2_learned_pdhg-1_kkt_robot`: 9.67e-06

### 6.4 建议

**立即可用的最佳配置**:
1. **Acker 机器人**: 使用 `acker_learned_prox_kkt_tuned_robot_2`
   - 配置: Learned-Prox + KKT (w_kkt=1e-3, kkt_rho=0.50)
   - 性能: 相比基线改进 85%+
   - 训练: 2500 epochs, batch_size=256, lr=5e-5

2. **Diff 机器人**: 使用 `diff_learned_prox_kkt_tuned_robot_2`
   - 配置: Learned-Prox + KKT (w_kkt=1e-4, kkt_rho=0.10)
   - 性能: 相比基线改进 79%+
   - 训练: 2500 epochs, batch_size=256, lr=5e-5

**需要进一步研究的方向**:
1. **PDHG 展开优化**
   - 当前 PDHG-1 单独使用时训练不稳定
   - 建议: 调整 PDHG 相关超参数 (tau, sigma),或尝试更小的展开步数
   - 可能需要更长的训练时间或不同的学习率策略

2. **SE(2) 等变性改进**
   - 当前 SE(2) 编码在组合使用时效果不佳
   - 建议: 单独测试 SE(2) 的影响,或调整编码方式
   - 可能需要针对 SE(2) 设计专门的训练策略

3. **KKT 参数调优**
   - 不同机器人类型需要不同的 KKT 参数
   - Acker: w_kkt=1e-3, kkt_rho=0.50 效果较好
   - Diff: w_kkt=1e-4, kkt_rho=0.10 效果较好
   - 建议: 进行更系统的网格搜索或贝叶斯优化

4. **训练策略改进**
   - 考虑使用渐进式训练 (先训练基础模块,再逐步添加复杂模块)
   - 尝试不同的学习率衰减策略
   - 增加训练轮数以确保充分收敛

**不建议使用的配置**:
- ❌ 单独使用 PDHG-1 (训练不稳定)
- ❌ SE(2) + PDHG-1 + KKT 组合在 Acker 上 (训练未收敛)
- ❌ 单独使用 Learned-Prox 在 Acker 上 (性能不如基线)

---

**报告结束**
