# 机器人导航国内外研究现状

## 一、研究背景及意义

随着全球能源转型战略的深入推进，新能源汽车产业正经历前所未有的高速发展。截至2024年底，我国新能源汽车保有量已突破3140万辆，较2023年底增长超过50%，成为全球最大的新能源汽车市场[1]。这一快速增长得益于国家层面的系统性政策支持：国务院办公厅于2020年11月发布的《新能源汽车产业发展规划(2021-2035年)》(国办发〔2020〕39号)明确将充电基础设施纳入新型基础设施建设工程[2]；国家发展改革委等六部门于2025年10月联合印发的《电动汽车充电设施服务能力"三年倍增"行动方案(2025-2027年)》(发改能源〔2025〕1250号)提出到2027年充电设施服务能力实现倍增的目标[3]；中共中央于2025年10月发布的《关于制定国民经济和社会发展第十五个五年规划的建议》明确提出加快建设新型能源体系，推动充电基础设施与新能源汽车协同发展[4]。这些政策充分体现了国家对充电基础设施柔性化、智能化升级的战略重视。

然而，在新能源汽车保有量快速增长的同时，充电基础设施建设面临着深层次的结构性矛盾。尽管截至2024年底全国充电设施总数已达1281.8万台，车桩比降至2.45:1[5]，但充电服务的时空分布失衡问题依然突出。一方面，一线城市公共充电桩利用率普遍不足30%，设备日均使用时长仅2-3小时，闲置率超过70%[6]；另一方面，三四线城市及偏远地区存在"车多桩少"的结构性短缺，老旧小区因电力扩容困难导致充电桩安装率不足10%[7]。更为严峻的是，在节假日高峰时段，高速公路服务区、景区停车场等场景频繁出现充电排队现象——2024年国庆假期期间，全国超三分之一高速公路服务区充电桩满负荷运行，部分服务区排队时长超过2小时[8]。这种时空错配不仅造成了充电资源的严重浪费，更制约了新能源汽车的大规模推广应用。传统固定式充电桩受限于电网布局、土地资源和建设周期，难以灵活响应动态变化的充电需求，亟需探索新型充电服务模式。

移动储能式充电机器人作为一种突破传统充电模式的创新解决方案，通过储能式设计实现离网充电功能，结合自主移动能力实现"桩找车"服务模式，为解决上述结构性矛盾提供了技术路径。相较于传统固定式充电桩，移动充电机器人具有三方面显著优势：第一，空间灵活性——无需依赖固定电网接入点，可根据实时需求动态调度至任意充电场景，有效解决老旧小区电力扩容难、地下停车场空间受限等问题；第二，时间经济性——通过智能调度算法实现设备利用率从传统充电桩的30%提升至60%以上，利用峰谷电价差实现储能套利，降低运营成本；第三，应急保障性——在新能源车辆突发缺电时提供即时充电服务，相较于传统道路救援成本降低60%-80%[9]。然而，移动充电机器人的核心技术挑战在于如何实现复杂动态环境下的自主导航与精准定位。

自主导航技术是移动充电机器人实现智能化服务的关键支撑，其技术难度远超传统工业机器人。移动充电机器人需要在开放式、非结构化的真实场景中运行，面临三方面核心挑战：第一，环境感知的鲁棒性——需要在光照变化、天气干扰、动态障碍物等复杂条件下实现高精度环境建模，传统基于单一传感器的感知方案难以满足全天候、全场景的可靠性要求；第二，路径规划的实时性——需要在毫秒级时间内生成满足机器人动力学约束的可行路径，并在动态环境中实时调整，传统离线规划方法无法应对突发障碍物和交通参与者的随机行为；第三，泊车充电的精准性——充电枪与车辆充电口的对接精度要求达到厘米级(误差<10cm)，这对机器人的定位精度和运动控制提出了极高要求。这些挑战的本质在于如何在保证安全性的前提下，实现高效、鲁棒、精准的自主导航决策。

由以上分析可知，针对移动充电机器人在复杂动态环境下的自主导航问题，现有技术在安全性、可解释性和实时性等方面尚存在一定的局限性。针对密集障碍场景下导航系统的约束满足性问题和基于学习方法的泛化性不足及安全保障缺失的挑战，本研究面向移动储能式充电机器人应用场景研究基于模型的学习导航方法，设计高可靠性、强泛化性、可解释的端到端导航策略，旨在为移动充电机器人自主导航提出可信赖的解决方案。该研究方向符合国际前沿技术发展趋势，能够促进移动充电机器人技术路线落地商用，为新能源汽车充电基础设施的智能化升级提供技术支撑。

## 二、从模块化架构到端到端学习的范式演进

在机器人导航领域,传统的模块化架构长期占据主导地位,其核心思想是将复杂的导航任务分解为感知、建图、规划和控制等相对独立的子模块[10]。这种设计哲学的优势在于各模块职责明确、便于独立开发和调试,因而在工业界得到广泛应用。然而,模块化架构面临着本质性的挑战:信息在模块间传递时不可避免地发生损失和失真。具体而言,感知模块输出的几何表示(如边界框、凸包等)往往无法完整刻画真实世界物体的复杂形状,这种表示误差在后续模块中被放大,最终导致规划器不得不采用过于保守的安全裕度[10]。更为严重的是,当环境中障碍物密集分布时,这种保守策略可能使机器人陷入局部死锁,无法找到可行路径。

针对模块化方法的固有缺陷,学术界和工业界近年来掀起了向端到端学习范式转变的浪潮[11-13]。端到端方法的核心理念是建立从原始传感器数据到控制指令的直接映射,从而绕过中间表示带来的信息瓶颈。早期的端到端尝试主要依赖单一的深度神经网络进行端到端的模仿学习,但这类方法在泛化性和可解释性方面表现不佳。随着研究的深入,新一代端到端方法开始采用模块化的网络架构,但与传统模块化方法存在本质区别:其一,模块间传递的是高维特征表示而非离散的几何符号;其二,通过注意力机制等手段实现模块间的双向信息流动;其三,整个系统通过端到端的梯度反向传播进行联合优化[10]。这种设计在自动驾驶领域取得了显著成功,例如Hu等人提出的UniAD框架通过任务查询机制实现了感知、预测和规划的深度耦合[14]。当前主流的端到端自动驾驶系统普遍采用基于Transformer的架构,通过多视角图像生成鸟瞰图表示[15],进而构建占用栅格地图用于轨迹规划[16]。

尽管端到端方法在自动驾驶等结构化场景中展现出巨大潜力,但其在计算效率、泛化能力和可解释性等方面仍面临诸多挑战。从计算效率角度看,传统端到端架构中BEV表示的生成过程往往成为性能瓶颈。为此,Jia等人提出的DriveTransformer通过纯Transformer架构直接处理多视角图像,省去了显式的BEV构建步骤,在保持决策质量的同时显著提升了推理速度[17]。从泛化能力角度看,早期端到端模型对训练数据分布的依赖性较强,在分布外场景中性能急剧下降。近期研究开始探索将大规模预训练模型引入导航任务,例如Cheng等人提出的NaVILA框架将视觉-语言-动作进行统一建模,使腿式机器人能够理解自然语言指令并执行相应的导航任务,展示了多模态基础模型在提升泛化能力方面的潜力[18]。针对非结构化环境中的导航难题,Weerakoon等人提出的VAPOR方法通过离线强化学习在密集植被环境中实现了鲁棒的腿式机器人导航[19]。这些工作共同推动了端到端方法从单一的映射学习向更加通用、灵活的智能系统演进。

然而,端到端学习范式的根本性挑战在于其"黑盒"特性导致的可解释性缺失[10]。这一问题在安全关键型应用中尤为突出:一方面,网络决策的不透明性使得系统调试和故障诊断异常困难;另一方面,缺乏明确的安全保障机制使得端到端系统难以通过严格的安全认证。为应对可解释性挑战,部分研究尝试将符号知识融入神经网络决策过程。例如,Cai等人提出的检索增强推理框架通过将交通规则等先验知识编码到大语言模型中,使决策过程具备一定的可追溯性[20]。黄昭彦等人则从系统架构层面出发,提出了基于信息融合的安全决策方法,通过显式建模感知-预测-规划的因果关系来增强系统的可解释性[21]。尽管这些工作在一定程度上缓解了可解释性问题,但现有方法大多局限于事后分析,难以在运行时提供形式化的安全保证。此外,端到端系统在处理长尾场景和对抗性扰动时的脆弱性仍未得到根本解决,这些因素共同制约了端到端方法在实际部署中的可信度。

## 二、基于模型方法与数据驱动方法的对比与融合

无论是模块化架构还是端到端框架,其核心算法可从方法论层面划分为基于模型(model-based)和基于学习(learning-based)两大类[11]。基于模型的方法通过数学建模显式刻画系统动力学、环境约束和优化目标,其优势在于具有明确的物理意义和理论保证。经典的基于模型方法包括:基于图搜索的方法(如A*算法)通过离散化配置空间并搜索最优路径;基于采样的方法(如RRT及其变体)通过随机采样探索高维配置空间;基于优化的方法则将导航问题建模为约束优化问题,通过求解最优控制序列生成轨迹[11]。

在密集障碍环境的导航场景中,基于优化的方法因其能够显式处理动力学约束并优化多目标性能指标而备受青睐[10]。然而,这类方法的计算复杂度随问题规模呈指数级增长:碰撞避免约束的数量与障碍物数量和预测时域长度成正比,当考虑障碍物的精确几何形状时,约束数量进一步膨胀。为缓解计算负担,研究者们提出了多种加速策略。Zhang等人提出的OBCA算法通过对偶理论将非凸的碰撞避免约束转化为凸约束,并结合时空分解技术实现了全形状机器人的实时规划[10]。然而,当环境中障碍物数量达到数十个时,即使采用这些优化技术,求解频率仍难以满足实时性要求。为此,部分研究选择牺牲约束的精确性以换取计算效率,例如采用中心点距离、符号距离函数近似或时空走廊等简化表示[22,23]。另一种加速思路是将硬约束松弛为软约束,如EGO规划器通过在目标函数中引入惩罚项来隐式处理碰撞避免[24]。尽管这些近似方法可实现百赫兹级的求解频率,但在密集场景中往往因约束违反而导致规划失败[10]。

与基于模型方法的显式建模思路不同,基于学习的方法通过数据驱动的方式隐式学习从感知到动作的映射关系,从而避免了对精确系统模型的依赖[10]。这一特性使得学习方法在模型难以精确建立的复杂系统中具有独特优势,因而成为端到端导航研究的重要方向。在众多学习范式中,强化学习因其能够通过试错机制自主探索最优策略而受到广泛关注。强化学习的核心思想是通过最大化累积奖励来优化策略网络,使智能体在与环境的交互中逐步学会完成导航任务。这一范式在动态避障场景中表现出色,能够直接从障碍物的运动模式中学习反应策略。近年来,深度强化学习在密集环境导航中取得了一系列进展。例如,Alexander等人提出的自适应紧急响应方法通过深度强化学习实现了机器人在动态人群中的安全导航[25]。然而,强化学习方法的性能高度依赖于训练数据的分布特性,这导致其在仿真环境中训练的策略往往难以直接迁移到真实世界。更为棘手的是,在密集场景导航中设计合适的奖励函数本身就是一个开放性难题:过于稀疏的奖励导致学习效率低下,而过于密集的奖励则可能引入人为偏差[10]。

为应对纯数据驱动方法在安全性和泛化性方面的不足,近年来涌现出一系列将形式化安全保障机制融入学习框架的研究工作。其中,控制障碍函数(Control Barrier Function, CBF)作为一种能够提供前向不变性保证的数学工具,在学习型导航系统中得到广泛应用。Keyumarsi等人提出了基于LiDAR点云在线合成CBF的方法,使机器人能够在未知环境中实时构建安全约束[26]。针对多智能体协同导航中的死锁问题,Chandra等人提出了离散时间CBF框架,通过分布式优化实现了无死锁的多机器人导航[27]。在动态环境导航方面,Shayan等人将指数型CBF与模型预测控制相结合,通过在加加速度层面施加约束实现了四旋翼飞行器的快速反应式避障[28]。此外,Stanford大学ARMLab提出的SAFER-Splat方法创新性地将高斯溅射地图与CBF相结合,实现了在线环境重建与安全导航的统一[29]。在国内,中国科学院自动化研究所李浩然副研究员针对复杂动态环境开展了深度强化学习导航策略的系统性研究[30],北京理工大学方浩教授团队在形式化方法与多智能体博弈方面取得了重要进展[31],上海交通大学殷翔教授团队则在时序逻辑约束下的强化学习路径规划方面进行了深入探索[32]。尽管这些工作在一定程度上增强了学习方法的安全性,但现有CBF方法大多依赖于离线设计的障碍函数,难以适应环境的动态变化和不确定性,且在高维状态空间中构造满足李普希茨连续性的CBF仍然是一个理论难题。

鉴于基于模型方法的可解释性优势和基于学习方法的适应性优势,近年来兴起了一股将两者深度融合的研究浪潮[10]。这种融合并非简单的方法叠加,而是在方法论层面探索如何将物理先验、优化结构和数据驱动学习有机结合。具体而言,基于模型的学习方法主要包括以下几种范式:第一,通过神经网络近似复杂的动力学模型或优化求解器,将传统的迭代优化过程展开为前馈神经网络,从而实现快速推理,神经MPC即属于此类;第二,利用学习方法生成高质量的初始解或候选轨迹集,以缩小后续优化算法的搜索空间,例如MPNet通过学习启发式函数加速运动规划[33];第三,将优化问题中的超参数(如代价函数权重、动力学模型参数等)视为可学习变量,通过可微分优化技术实现端到端的参数学习,OptNet框架即是这一思路的代表性工作[34]。

在基于模型的学习方法中,算法展开(Algorithm Unrolling)作为一种将优化算法的迭代结构显式嵌入神经网络的技术,近年来受到广泛关注。其核心思想是将传统优化算法的每次迭代映射为神经网络的一层,从而使网络架构天然继承优化算法的收敛性质和物理意义。这种设计不仅提升了网络的可解释性,还能通过端到端训练自适应调整算法参数。Zhou等人提出的深度展开网络将原始对偶混合梯度(PDHG)算法展开为深度神经网络,并引入循环动量机制加速收敛,在非线性逆问题求解中展现出优于传统迭代方法的性能[35]。在机器人运动规划领域,Ni等人提出的物理信息神经网络(Physics-Informed Neural Networks)通过在损失函数中显式编码物理约束,实现了在约束流形上的高效运动规划[36]。在此基础上,Ni等人进一步提出了物理信息时序差分度量学习方法,通过自监督学习机制构建满足物理约束的距离度量,显著提升了规划算法的可扩展性[37]。尽管算法展开方法在图像重建等领域取得了成功,但其在机器人导航中的应用仍面临诸多挑战:一方面,如何设计适用于高维非凸优化问题的展开架构尚无统一范式;另一方面,如何严格保证展开网络输出的对偶变量满足可行性约束(如非负性、范数约束等)仍是一个理论开放问题。

与算法展开互为补充的另一重要技术是可微分优化(Differentiable Optimization),其核心在于将优化求解过程嵌入神经网络的计算图中,从而实现从损失函数到优化问题参数的端到端梯度传播。这一技术使得优化问题中的代价函数权重、约束参数等超参数可以通过反向传播自动学习,而无需人工调参。随着GPU并行计算能力的提升,可微分MPC在实时控制中的应用潜力逐渐显现。Adabag等人提出了面向GPU的可微分MPC实现框架,通过并行化KKT条件求解显著提升了计算吞吐量[38]。Gurumurthy等人提出的深度平衡模型预测控制(DEQ-MPC)将隐式层理论引入MPC,通过求解不动点方程实现了内存高效的梯度计算[39]。Romero等人则提出了演员-评论家MPC架构,将强化学习的策略梯度方法与可微分优化相结合,实现了模型参数和控制策略的联合学习[40]。这些工作共同推动了学习型优化器的发展,使得优化算法能够从数据中自适应调整其内部参数。然而,现有可微分优化方法在理论和实践层面仍存在诸多挑战:首先,梯度计算的数值稳定性问题尚未得到充分解决,特别是在约束激活集频繁切换时容易出现梯度爆炸或消失;其次,如何在学习过程中保证优化问题的可行性和鲁棒性缺乏系统性研究;最后,在动态环境中实现在线参数自适应的同时保证实时性和安全性,仍然是一个开放性难题。

为从根本上解决神经网络输出违反物理约束的问题,投影层(Projection Layer)技术应运而生。该技术的核心思想是在神经网络的输出端引入可微分的投影算子,将可能违反约束的网络输出强制映射到可行域内。Chen等人提出的同胚投影方法通过构造从欧氏空间到约束流形的同胚映射,在保证约束严格满足的同时维持了梯度的连续性和可微性[41]。这类方法的优势在于投影层通常为零参数或少参数模块,不会显著增加模型复杂度。然而,现有投影方法主要针对凸约束集合设计,当面对非凸约束或高维耦合约束时,投影操作的计算复杂度急剧上升,难以满足实时控制的时延要求。此外,投影操作的引入可能导致梯度病态问题:当网络输出远离可行域时,投影操作的雅可比矩阵可能出现病态,引发梯度消失或爆炸,从而影响训练的稳定性和收敛性。如何设计兼顾约束可行性、计算效率和梯度性质的投影算子,仍然是一个具有挑战性的研究课题。

综合上述研究进展可以看出,基于模型的学习方法正在成为机器人导航领域的重要研究方向,其本质是在保留物理模型可解释性的同时引入数据驱动的自适应能力。然而,现有工作在理论和应用层面仍存在诸多局限:首先,算法展开方法虽然继承了优化算法的结构,但如何理论保证展开网络的收敛性和最优性尚缺乏系统性分析;其次,可微分优化方法在处理不等式约束和互补约束时的梯度计算仍面临数值稳定性挑战;再次,投影层技术在非凸约束下的计算效率和梯度性质需要进一步改进;最后,如何将形式化验证方法与神经MPC相结合,实现可证明的安全保障,仍然是一个开放性问题。从应用场景来看,尽管端到端方法在结构化道路场景(如自动驾驶)中取得了显著成功,基于优化的方法在稀疏障碍环境中也已相对成熟,但在密集非结构化场景(如点云导航)中如何保证神经网络输出严格满足物理约束,以及如何在多智能体交互场景中兼顾实时性、安全性和可解释性,仍然存在大量未解决的科学问题。这些挑战也正是本文研究工作的出发点和主要贡献方向。

## 参考文献

[1] 国家统计局. "中华人民共和国2024年国民经济和社会发展统计公报." 2025年2月28日.

[2] 国务院办公厅. "关于印发新能源汽车产业发展规划(2021-2035年)的通知." 国办发〔2020〕39号, 2020年11月2日.

[3] 国家发展改革委, 国家能源局, 工业和信息化部, 住房城乡建设部, 交通运输部, 市场监管总局. "关于印发《电动汽车充电设施服务能力'三年倍增'行动方案(2025-2027年)》的通知." 发改能源〔2025〕1250号, 2025年10月15日. https://www.ndrc.gov.cn/xxgk/zcfb/tz/202510/t20251015_1401011.html

[4] 中共中央. "关于制定国民经济和社会发展第十五个五年规划的建议." 2025年10月28日. https://www.gov.cn/zhengce/202510/content_7046050.htm

[5] 中国电动汽车充电基础设施促进联盟. "2025年一季度全国公共充电基础设施增长情况分析." 2025年4月16日. https://www.evcipa.org.cn/newsinfo/8310587.html

[6] 平顶山市政协. "关于加快建设新能源汽车充电设施相关建议的提案." 2024年7月23日. https://pds.gov.cn/contents/60955/410266.html

[7] 麦肯锡公司. "2024麦肯锡中国汽车消费者洞察报告." 2024年3月.

[8] 上海市经济和信息化委员会. "上海高速充电量创新高 长途充电焦虑将逐步缓解." 2024年10月12日. https://sheitc.sh.gov.cn/jjyw/20241012/b8cd23dfab894aa990b5dc38ee5f8d36.html

[9] 项目组调研数据, 基于百里杜鹃景区停车场和高速公路服务区应用测试结果, 2024年.

[10] Han, R., Wang, S., Wang, S., Zhang, Z., Chen, J., Lin, S., Li, C., Xu, C., Eldar, Y. C., Hao, Q., and Pan, J. "NeuPAN: Direct point robot navigation with end-to-end model-based learning." IEEE Transactions on Robotics, 2025.

[11] Bojarski, M., et al. "End to end learning for self-driving cars." arXiv preprint arXiv:1604.07316, 2016.

[12] Codevilla, F., et al. "End-to-end driving via conditional imitation learning." IEEE International Conference on Robotics and Automation (ICRA), 2018.

[13] Chen, D., et al. "Learning by cheating." Conference on Robot Learning (CoRL), 2019.

[14] Hu, Y., et al. "Planning-oriented autonomous driving." IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.

[15] Li, Z., et al. "BEVFormer: Learning bird's-eye-view representation from multi-camera images via spatiotemporal transformers." European Conference on Computer Vision (ECCV), 2022.

[16] Tian, X., Jiang, T., Yun, L., Mao, Y., Yang, H., Wang, Y., Wang, Y., and Zhao, H. "Occ3D: A large-scale 3D occupancy prediction benchmark for autonomous driving." Advances in Neural Information Processing Systems (NeurIPS), Datasets and Benchmarks Track, 2023.

[17] Jia, X., You, J., Zhang, Z., and Yan, J. "DriveTransformer: Unified transformer for scalable end-to-end autonomous driving." International Conference on Learning Representations (ICLR), 2025.

[18] Cheng, D., et al. "NaVILA: Legged robot vision-language-action model for navigation." Conference on Robot Learning (CoRL), 2024.

[19] Weerakoon, K., et al. "VAPOR: Legged robot navigation in unstructured outdoor environments using offline reinforcement learning." IEEE International Conference on Robotics and Automation (ICRA), 2024.

[20] Cai, T., Liu, Y., Zhou, Z., Ma, H., Zhao, S. Z., Wu, Z., and Ma, J. "Driving with regulation: Interpretable decision-making for autonomous vehicles with retrieval-augmented reasoning via LLM." arXiv preprint arXiv:2410.04759, 2024.

[21] 黄昭彦, 杨烁, 吴建华, 范佳琦, 田炜, 殷翔, 方浩, 褚洪庆, 高炳钊. "基于信息融合的智能网联汽车安全交互决策." 自动化学报, 2025, 51(9): 1883-1898.

[22] Gao, F., et al. "Teach-repeat-replan: A complete and robust system for aggressive flight in complex environments." IEEE Transactions on Robotics, 2020.

[23] Tordesillas, J., et al. "FASTER: Fast and safe trajectory planner for flights in unknown environments." IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2019.

[24] Zhou, X., et al. "EGO-Planner: An ESDF-free gradient-based local planner for quadrotors." IEEE Robotics and Automation Letters, 2021.

[25] Alexander, A., et al. "Adaptive emergency response and dynamic crowd navigation for mobile robot using deep reinforcement learning." Frontiers in Robotics and AI, 2025, 12:1612392.

[26] Keyumarsi, S., Atman, M. W. S., and Gusrialdi, A. "LiDAR-based online control barrier function synthesis for safe navigation in unknown environments." IEEE Robotics and Automation Letters, vol. 9, no. 2, pp. 1043-1050, 2024.

[27] Chandra, R., Zinage, V., Esselink, J., and Stone, P. "Deadlock-free, safe, and decentralized multi-robot navigation in social mini-games via discrete-time control barrier functions." Autonomous Robots, 2025, 49:12.

[28] Shayan, Z., Izadi, M., Scognamiglio, V., Simetti, E., and Lippiello, V. "Exponential control barrier function and model predictive control for jerk-level reactive motion planning of quadrotors." Control Engineering Practice, vol. 164, 106489, 2025.

[29] Chen, T., Swann, A., Gao, W., and Pavone, M. "SAFER-Splat: A control barrier function for safe navigation with online Gaussian splatting maps." IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025.

[30] 李浩然. "复杂动态环境下基于深度强化学习的机器人导航策略." 中国科学院自动化研究所, 2024.

[31] 方浩, 等. "基于数据驱动的多智能体规划识别与博弈围捕." 北京理工大学学报(自然科学版), 2024.

[32] 殷翔, 任晓华, 李少远. "基于强化学习的机器人复杂时序逻辑任务路径规划方法." 中国专利 CN114355947A, 2022.

[33] Qureshi, A. H., et al. "Motion planning networks: Bridging the gap between learning-based and classical motion planners." IEEE Transactions on Robotics, 2021.

[34] Amos, B., and Kolter, J. Z. "OptNet: Differentiable optimization as a layer in neural networks." International Conference on Machine Learning (ICML), 2017.

[35] Zhou, Q., Qian, J., Tang, J., and Li, J. "Deep unrolling networks with recurrent momentum acceleration for nonlinear inverse problems." Inverse Problems, vol. 40, no. 5, 055014, 2024.

[36] Ni, R., and Qureshi, A. H. "Physics-informed neural motion planning on constraint manifolds." IEEE International Conference on Robotics and Automation (ICRA), 2024.

[37] Ni, R., and Qureshi, A. H. "Physics-informed temporal difference metric learning for robot motion planning." International Conference on Learning Representations (ICLR), 2025.

[38] Adabag, E., Greiff, M., Subosits, J., and Lew, T. "Differentiable model predictive control on the GPU." arXiv preprint arXiv:2510.06179, 2025.

[39] Gurumurthy, S., Nguyen, K., Bishop, A. L., Kolter, J. Z., and Manchester, Z. "DEQ-MPC: Deep equilibrium model predictive control." Conference on Robot Learning (CoRL), 2025.

[40] Romero, A., Song, Y., and Scaramuzza, D. "Actor-critic model predictive control." IEEE International Conference on Robotics and Automation (ICRA), 2024.

[41] Chen, M. H., and Low, K. H. "Homeomorphic projection to ensure neural-network solution feasibility for constrained optimization." Journal of Machine Learning Research, vol. 25, pp. 1-55, 2024.

