# 核心模块实验性能分析报告

**实验日期**: 2025-10-26  
**实验结果目录**: `core_modules_20251026_092238_一次成功的实验，但是时间偏高`  
**分析日期**: 2025-10-26

---

## 执行摘要

本次实验虽然成功率达到要求，但时间性能普遍偏高。经过深入分析，主要发现：

### 关键发现

1. **FlexPDHG算法开销**: flex_learned配置相比baseline平均增加 **+13.8%** 的forward时间（+5.34ms）
2. **Acker运动学模型问题**: 在acker模型下，FlexPDHG的性能下降更明显（平均+20.6%）
3. **异常慢的测试用例**: `corridor_acker_flex_roi` 达到 **134.79ms**，比baseline慢 **171.2%**
4. **ROI策略效果**: 大部分场景下ROI能降低时间，但在corridor_acker场景下反而增加95%

### 优化潜力

- **短期优化**: 通过参数调整可降低10-20%的时间开销
- **中期优化**: 优化FlexPDHG实现可降低20-30%的时间开销
- **长期优化**: 算法层面改进可能降低30-50%的时间开销

---

## 1. 数据层面分析

### 1.1 总体时间对比

| 配置 | 平均单步时间 | 平均Forward时间 | 平均总时间 | Forward占比 |
|------|-------------|----------------|-----------|------------|
| **baseline** | 39.15 ms | 38.68 ms | 6.34 s | 98.8% |
| **flex_learned** | 44.46 ms | 44.03 ms | 6.93 s | 99.0% |
| **flex_roi** | 44.69 ms | 44.28 ms | 5.40 s | 99.1% |

**关键观察**:
- Forward时间占总时间的98.8%以上，说明性能瓶颈主要在算法本身
- flex_learned比baseline慢13.8%，说明FlexPDHG前端引入了额外开销
- flex_roi的总时间反而更短（-14.9%），因为步数减少（ROI提高了规划效率）

### 1.2 相对Baseline的时间增长

```
flex_learned:
  - forward时间增长: +13.8%
  - 总时间增长: +9.3%

flex_roi:
  - forward时间增长: +14.5%
  - 总时间增长: -14.9% (步数减少导致)
```

### 1.3 时间开销最大的测试用例 TOP 5

| 排名 | 场景 | 运动学 | 配置 | Forward时间 | 总时间 |
|-----|------|--------|------|------------|--------|
| 1 | corridor | acker | flex_roi | **134.79 ms** | 9.07 s |
| 2 | corridor | acker | flex_learned | 69.13 ms | 14.52 s |
| 3 | dyna_non_obs | acker | flex_learned | 52.83 ms | 6.41 s |
| 4 | corridor | acker | baseline | 49.70 ms | 2.16 s |
| 5 | dyna_non_obs | acker | baseline | 46.32 ms | 4.76 s |

**关键发现**: 
- **corridor_acker_flex_roi** 是唯一超过100ms的异常慢测试用例
- acker运动学模型在corridor场景下表现异常
- 该场景的baseline也比其他场景慢（49.70ms）

### 1.4 按场景和运动学模型的详细分析

#### Diff运动学模型表现

| 场景 | baseline | flex_learned | flex_roi | flex vs baseline |
|------|----------|--------------|----------|-----------------|
| convex_obs | 38.17 ms | 34.62 ms | 29.38 ms | **-9.3%** ✓ |
| corridor | 42.40 ms | 45.35 ms | 36.14 ms | +7.0% |
| dyna_non_obs | 38.81 ms | 43.50 ms | 32.54 ms | +12.1% |
| non_obs | 34.31 ms | 34.84 ms | 29.52 ms | +1.5% |
| pf_obs | 35.10 ms | 36.15 ms | 30.08 ms | +3.0% |

**观察**: Diff模型下，flex_learned在convex_obs场景下反而更快（-9.3%），其他场景增长较小（1.5%-12.1%）

#### Acker运动学模型表现

| 场景 | baseline | flex_learned | flex_roi | flex vs baseline |
|------|----------|--------------|----------|-----------------|
| convex_obs | 34.67 ms | 41.73 ms | 34.61 ms | **+20.4%** ⚠️ |
| corridor | 49.70 ms | 69.13 ms | 134.79 ms | **+39.1%** ⚠️⚠️ |
| dyna_non_obs | 46.32 ms | 52.83 ms | 40.12 ms | +14.1% |
| non_obs | 33.48 ms | 41.29 ms | 37.76 ms | **+23.3%** ⚠️ |
| pf_obs | 33.88 ms | 40.85 ms | 37.88 ms | **+20.6%** ⚠️ |

**关键问题**: 
- Acker模型下，flex_learned普遍比baseline慢20%以上
- corridor_acker_flex_roi异常慢（+171.2%），需要重点排查

---

## 2. 配置层面分析

### 2.1 当前配置参数

从 `example/corridor/acker/planner.yaml` 和实验配置中提取的关键参数：

```yaml
# MPC配置
receding: 10              # 预测时域步数
step_time: 0.2            # 时间步长
ref_speed: 4              # 参考速度

# PAN算法配置
pan:
  iter_num: 2             # PAN迭代次数
  dune_max_num: 100       # DUNE最大点数
  nrmp_max_num: 14        # NRMP最大点数
  iter_threshold: 0.1     # 收敛阈值

# FlexPDHG配置（从训练配置推断）
front_J: 2                # PDHG展开步数
front_hidden: 32          # 隐藏层维度
front_learned: true       # 启用学习的prox
front_tau: 0.5            # 原始步长
front_sigma: 0.5          # 对偶步长

# ROI配置
roi:
  cone:
    fov_base_deg: 90.0    # 基础视野角度
    r_max_m: 7.0          # 最大可达距离
    expansion_factor: 100.0
  guardrail:
    n_min: 15             # 最少点数要求
```

### 2.2 配置问题识别

#### 问题1: FlexPDHG展开步数可能过多

**当前值**: `front_J: 2`  
**影响**: 每个PDHG步骤包含：
- y-update（对偶变量更新）
- mu-update（原始变量更新）
- learned-prox（学习的近端算子）
- 投影操作

**建议**: 
- 尝试 `front_J: 1`，可能降低30-40%的FlexPDHG开销
- 对于实时应用，J=1通常足够

#### 问题2: PAN迭代次数

**当前值**: `iter_num: 2`  
**影响**: 每次forward调用会执行2次完整的DUNE+NRMP循环

**建议**:
- 监控实际收敛情况，如果第1次迭代后已经收敛，可以设置 `iter_num: 1`
- 或者调整 `iter_threshold` 使其更容易提前终止

#### 问题3: ROI guardrail参数

**当前值**: `n_min: 15`  
**问题**: 在corridor_acker场景下，ROI可能触发过多的放松迭代

**建议**:
- 增加 `n_min` 到 20-25，减少放松次数
- 或者调整 `relax_step` 从1.15降低到1.10

### 2.3 推荐的优化配置

#### 配置方案A: 激进优化（优先性能）

```yaml
pan:
  iter_num: 1              # 减少到1次迭代
  dune_max_num: 80         # 从100降低到80
  nrmp_max_num: 12         # 从14降低到12

# FlexPDHG（需要重新训练模型）
front_J: 1                 # 减少到1步
```

**预期效果**: 降低30-40%的时间开销

#### 配置方案B: 保守优化（平衡性能和质量）

```yaml
pan:
  iter_num: 2              # 保持不变
  iter_threshold: 0.05     # 从0.1降低到0.05，更容易提前终止
  dune_max_num: 90         # 从100降低到90
  nrmp_max_num: 14         # 保持不变

roi:
  guardrail:
    n_min: 20              # 从15增加到20
    relax_step: 1.10       # 从1.15降低到1.10
```

**预期效果**: 降低10-20%的时间开销

---

## 3. 算法层面分析

### 3.1 FlexPDHG算法开销分解

FlexPDHG的forward方法包含以下步骤：

```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    # 1. 特征编码 (如果启用SE2)
    if self.se2_embed:
        feats_in = self._polar_embed(x)  # 极坐标嵌入
    else:
        feats_in = x
    
    # 2. 初始化
    h = self.encoder(feats_in)        # MLP编码
    mu = self.init_mu(h)              # 初始化mu
    y = self.init_y(h)                # 初始化y
    
    # 3. PDHG迭代 (J次)
    for j in range(self.J):
        # 3.1 y-update
        y = y + sigma * (mu @ self.G)
        y = y / y_norm.clamp(min=1.0)
        
        # 3.2 mu-update
        a_row = x @ self.G.t() - self.h.t()
        mu = mu + tau * (a_row - (y @ self.G.t()))
        
        # 3.3 learned-prox (如果启用)
        if self.use_learned_prox:
            z = mu @ self.G
            delta = self.prox_head(z)
            mu = mu + self.residual_scale * delta
        
        # 3.4 投影
        mu = self._project_mu_row(mu, self.G)
    
    return mu
```

### 3.2 性能瓶颈定位

#### 瓶颈1: 矩阵乘法操作

**位置**: 
- `mu @ self.G` (每次迭代2次)
- `x @ self.G.t()` (每次迭代1次)
- `y @ self.G.t()` (每次迭代1次)

**复杂度**: O(N * E * 2)，其中N是点数，E是边数（通常为4）

**优化建议**:
- 预计算 `G.t()` 避免重复转置
- 使用 `torch.mm` 替代 `@` 操作符（可能更快）
- 考虑使用 `torch.compile` (PyTorch 2.0+)

#### 瓶颈2: Learned-Prox网络

**位置**: `self.prox_head(z)`

**复杂度**: O(N * hidden * E)

**优化建议**:
- 减小 `front_hidden` 从32降低到16
- 简化prox_head网络结构（当前是2层MLP）
- 考虑使用更轻量的激活函数

#### 瓶颈3: 投影操作

**位置**: `self._project_mu_row(mu, self.G)`

```python
def _project_mu_row(self, mu: torch.Tensor, G: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    mu = mu.clamp(min=0.0)  # 非负投影
    v = mu @ G              # [N,2]
    v_norm = torch.norm(v, dim=1, keepdim=True)  # [N,1]
    scale = torch.where(v_norm > 1.0, 1.0 / v_norm, torch.ones_like(v_norm))
    mu = mu * scale
    return mu
```

**优化建议**:
- 使用 `torch.clamp_min_` 原地操作
- 避免 `torch.where`，使用 `torch.clamp_max`

### 3.3 Acker模型特殊问题

**观察**: Acker模型下FlexPDHG比Diff模型慢得多

**可能原因**:
1. **几何复杂度**: Acker机器人更大（4.6m x 1.6m vs 1.6m x 2.0m），边数可能更多
2. **约束数量**: Acker的运动学约束更复杂
3. **模型训练**: Acker模型的FlexPDHG可能训练不够充分

**验证方法**:
```python
# 检查G矩阵的大小
print(f"Diff G shape: {diff_robot.G.shape}")
print(f"Acker G shape: {acker_robot.G.shape}")
```

### 3.4 Corridor场景特殊问题

**corridor_acker_flex_roi异常慢的可能原因**:

1. **ROI放松循环**: 在狭窄走廊中，初始ROI可能选择的点太少，触发多次放松
2. **失败导致重规划**: 成功率为0，说明任务失败，可能陷入局部最优
3. **步数少但单步慢**: 只有67步但总时间9.07s，说明每步都很慢

**建议排查**:
- 查看该场景的ROI日志，统计放松次数
- 检查是否有异常的点云分布
- 分析失败原因（碰撞？超时？）

---

## 4. 代码层面分析

### 4.1 潜在的性能问题

#### 问题1: 重复的张量操作

**位置**: `neupan/blocks/flexible_pdhg.py`

```python
# 当前实现
for j in range(self.J):
    tau_j = tau_vals[j]
    sigma_j = sigma_vals[j]
    y, mu = self._step(x, y, mu, tau_j, sigma_j)
```

**问题**: 每次迭代都要索引 `tau_vals[j]`

**优化**:
```python
# 如果tau和sigma是标量，直接使用
if not self.learnable_steps:
    tau_j = self.tau
    sigma_j = self.sigma
```

#### 问题2: 不必要的设备转换

**位置**: `_prepare_step_sizes`

```python
def _prepare_step_sizes(self, device, dtype):
    tau_vals = self.tau.to(device=device, dtype=dtype).expand(self.J)
    sigma_vals = self.sigma.to(device=device, dtype=dtype).expand(self.J)
    return tau_vals, sigma_vals
```

**问题**: 每次forward都要转换设备

**优化**: 在 `__init__` 中就确保在正确设备上

#### 问题3: ROI选择的时间开销

**位置**: `neupan/neupan.py:_apply_roi`

```python
_t0 = time.perf_counter()
roi_output = self.roi_selector.select(...)
self.info["roi_time_ms"] = (time.perf_counter() - _t0) * 1000.0
```

**数据**: ROI平均耗时约70-145ms（从summary数据推断）

**问题**: ROI选择本身可能成为瓶颈

**优化建议**:
- 优化 `_reachability_cone_mask` 的实现
- 减少放松循环的次数
- 使用向量化操作替代循环

### 4.2 调试代码检查

**检查项**: 是否有未移除的调试代码

```bash
# 搜索可能的调试代码
grep -r "print(" neupan/blocks/
grep -r "import pdb" neupan/
grep -r "breakpoint()" neupan/
```

**建议**: 确保所有 `time_print` 在生产环境中设置为 `False`

### 4.3 内存分配问题

**潜在问题**: 频繁的张量创建和销毁

**检查方法**:
```python
import torch
torch.cuda.memory_summary()  # 如果使用GPU
```

**优化建议**:
- 使用原地操作（`_` 后缀）
- 预分配缓冲区
- 使用 `torch.no_grad()` 包裹推理代码

---

## 5. 优化建议总结

### 5.1 立即可执行的优化（无需修改代码）

| 优化项 | 当前值 | 建议值 | 预期效果 |
|--------|--------|--------|---------|
| `iter_num` | 2 | 1 | -20% |
| `dune_max_num` | 100 | 80-90 | -5% |
| `nrmp_max_num` | 14 | 12 | -3% |
| `iter_threshold` | 0.1 | 0.05 | -5% |
| `roi.guardrail.n_min` | 15 | 20 | -10% (ROI场景) |

**总预期效果**: 降低 **15-25%** 的时间开销

### 5.2 需要重新训练的优化

| 优化项 | 当前值 | 建议值 | 预期效果 |
|--------|--------|--------|---------|
| `front_J` | 2 | 1 | -30% |
| `front_hidden` | 32 | 16 | -10% |
| 简化prox_head | 2层MLP | 1层MLP | -5% |

**总预期效果**: 降低 **30-40%** 的FlexPDHG开销

### 5.3 需要代码修改的优化

1. **优化FlexPDHG实现**
   - 预计算 `G.t()`
   - 使用原地操作
   - 优化投影函数
   - **预期效果**: -10-15%

2. **优化ROI选择**
   - 向量化cone mask计算
   - 减少放松循环
   - **预期效果**: -20-30% (ROI场景)

3. **使用PyTorch编译**
   ```python
   if torch.__version__ >= "2.0":
       self.model = torch.compile(self.model)
   ```
   - **预期效果**: -10-20%

### 5.4 针对corridor_acker_flex_roi的特殊优化

**问题**: 该场景异常慢（134.79ms）且失败

**排查步骤**:
1. 运行单次测试，启用详细日志
2. 检查ROI放松次数
3. 分析失败原因
4. 检查点云分布

**可能的解决方案**:
- 调整ROI参数（增大初始FOV）
- 检查路径规划是否合理
- 考虑使用不同的ROI策略

---

## 6. 实验验证计划

### 6.1 配置优化实验

**实验1: 减少迭代次数**
```yaml
pan:
  iter_num: 1
```
**预期**: 降低20%时间，成功率保持

**实验2: 减少点数**
```yaml
pan:
  dune_max_num: 80
  nrmp_max_num: 12
```
**预期**: 降低5-8%时间，成功率略降

**实验3: 调整ROI参数**
```yaml
roi:
  guardrail:
    n_min: 20
    relax_step: 1.10
```
**预期**: corridor_acker场景改善

### 6.2 代码优化实验

**实验4: 优化FlexPDHG**
- 实现上述代码优化
- **预期**: 降低10-15%时间

**实验5: 重新训练J=1模型**
- 训练 `front_J: 1` 的模型
- **预期**: 降低30%时间

### 6.3 对比基准

| 场景 | 当前时间 | 目标时间 | 优化幅度 |
|------|---------|---------|---------|
| 平均forward | 44.03 ms | 30-35 ms | -20-30% |
| corridor_acker_flex_roi | 134.79 ms | <60 ms | -55% |

---

## 7. 结论

### 7.1 主要问题

1. **FlexPDHG算法开销**: 相比baseline增加13.8%，主要来自PDHG迭代和learned-prox
2. **Acker模型性能差**: 比Diff模型慢约10-20ms，需要针对性优化
3. **corridor_acker_flex_roi异常**: 需要深入排查ROI策略和场景特性

### 7.2 优化路线图

**短期（1-2天）**:
- 调整配置参数（iter_num, dune_max_num等）
- 排查corridor_acker问题
- **目标**: 降低15-25%时间

**中期（1-2周）**:
- 优化FlexPDHG代码实现
- 优化ROI选择算法
- **目标**: 降低30-40%时间

**长期（1-2月）**:
- 重新训练轻量级模型（J=1, hidden=16）
- 探索更高效的前端架构
- **目标**: 降低40-50%时间

### 7.3 下一步行动

1. ✅ 完成性能分析报告
2. ⏳ 执行配置优化实验（实验1-3）
3. ⏳ 排查corridor_acker_flex_roi问题
4. ⏳ 实现FlexPDHG代码优化
5. ⏳ 重新训练轻量级模型

---

**报告生成时间**: 2025-10-26  
**分析工具**: `test/analyze_performance.py`  
**可视化图表**: `performance_analysis/` 目录

